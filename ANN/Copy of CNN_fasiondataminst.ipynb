{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CNN_fasiondataminst.ipynb","provenance":[{"file_id":"1iMFr8divBWCIVECwXRHB_iumn8cP_SIq","timestamp":1623756879176}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"i48sRYH0W-Xt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623756956563,"user_tz":-420,"elapsed":43546,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"3ad80f50-4680-46b3-abf1-c8259ba5ea00"},"source":["pip install tensorflow==2.0.0-alpha0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.0.0-alpha0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/4e/402a4d7f21d03cd640b41376727a9ea2bac5a06d2556c04517878dad0c3d/tensorflow-2.0.0a0-cp37-cp37m-manylinux1_x86_64.whl (80.3MB)\n","\u001b[K     |████████████████████████████████| 80.3MB 56kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (1.34.1)\n","Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n","\u001b[K     |████████████████████████████████| 419kB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (1.19.5)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (0.12.0)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (0.36.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (3.12.4)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n","Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 30.3MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (0.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (57.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (1.0.1)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (1.5.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (4.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.7.4.3)\n","\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 2.0.0a0 which is incompatible.\u001b[0m\n","Installing collected packages: tf-estimator-nightly, keras-applications, tb-nightly, tensorflow\n","  Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","Successfully installed keras-applications-1.0.8 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yYHy58XOXPV1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623756957904,"user_tz":-420,"elapsed":1348,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"871b34a8-b789-4299-fd3c-00140e17b270"},"source":["import tensorflow as tf\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KD4uFXeFXTRq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623756958583,"user_tz":-420,"elapsed":685,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"b8b724c9-d380-4ff7-bdba-ffc600396f21"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_U0YkxgyX0xl","executionInfo":{"status":"ok","timestamp":1623756958584,"user_tz":-420,"elapsed":10,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}}},"source":["y_train = tf.keras.utils.to_categorical(y_train, num_classes=None)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes=None)\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1ayamNhXUVE","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1623756959104,"user_tz":-420,"elapsed":529,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"a3f3285c-01ac-4e5f-e09a-0660aedc40c3"},"source":["# We use the Sequential model in keras which is used 99% of the time \n","model = tf.keras.Sequential() \n","# We add our first convolutional layer with 32 neurons and filter size of 3 x 3\n","model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n","# We add our max pooling layer \n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n","# We flatten the features \n","model.add(tf.keras.layers.Flatten()) \n","#We add a second convolutional layer \n","model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu')) \n","# Our dropout layer \n","model.add(tf.keras.layers.Dropout(0.25)) \n","# A fully connected layer \n","model.add(tf.keras.layers.Dense(128, activation='relu')) \n","# Another dropout layer with more dropouts \n","model.add(tf.keras.layers.Dropout(0.5)) \n","# We add an output layer that uses softmax activation for the 10 classes \n","model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, batch_size=128, epochs=12, verbose=1, validation_data=(x_test, y_test))\n","\n","score = model.evaluate(x_test, y_test, verbose=0) \n","print('Test loss:', score[0]) \n","print('Test accuracy:', score[1])\n"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3a68ee92bccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#We add a second convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Our dropout layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         raise TypeError('All layers in a Sequential model '\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# the corresponding TF subgraph inside `backend.get_graph()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 589\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    122\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 5408]"]}]},{"cell_type":"code","metadata":{"id":"D7KCwjcydvQe","executionInfo":{"status":"aborted","timestamp":1623756959103,"user_tz":-420,"elapsed":525,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}}},"source":["# baseline cnn model for fashion mnist\n","from numpy import mean\n","from numpy import std\n","from matplotlib import pyplot\n","from sklearn.model_selection import KFold\n","from keras.datasets import fashion_mnist\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","\n","# load train and test dataset\n","def load_dataset():\n","\t# load dataset\n","\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n","\t# reshape dataset to have a single channel\n","\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n","\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n","\t# one hot encode target values\n","\ttrainY = to_categorical(trainY)\n","\ttestY = to_categorical(testY)\n","\treturn trainX, trainY, testX, testY\n","\n","# scale pixels\n","def prep_pixels(train, test):\n","\t# convert from integers to floats\n","\ttrain_norm = train.astype('float32')\n","\ttest_norm = test.astype('float32')\n","\t# normalize to range 0-1\n","\ttrain_norm = train_norm / 255.0\n","\ttest_norm = test_norm / 255.0\n","\t# return normalized images\n","\treturn train_norm, test_norm\n","\n","# define cnn model\n","def define_model():\n","\tmodel = Sequential()\n","\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n","\tmodel.add(MaxPooling2D((2, 2)))\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n","\tmodel.add(Dense(10, activation='softmax'))\n","\t# compile model\n","\topt = SGD(lr=0.01, momentum=0.9)\n","\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\treturn model\n","\n","# evaluate a model using k-fold cross-validation\n","def evaluate_model(dataX, dataY, n_folds=5):\n","\tscores, histories = list(), list()\n","\t# prepare cross validation\n","\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n","\t# enumerate splits\n","\tfor train_ix, test_ix in kfold.split(dataX):\n","\t\t# define model\n","\t\tmodel = define_model()\n","\t\t# select rows for train and test\n","\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n","\t\t# fit model\n","\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n","\t\t# evaluate model\n","\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n","\t\tprint('> %.3f' % (acc * 100.0))\n","\t\t# append scores\n","\t\tscores.append(acc)\n","\t\thistories.append(history)\n","\treturn scores, histories\n","\n","# plot diagnostic learning curves\n","def summarize_diagnostics(histories):\n","\tfor i in range(len(histories)):\n","\t\t# plot loss\n","\t\tpyplot.subplot(211)\n","\t\tpyplot.title('Cross Entropy Loss')\n","\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n","\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n","\t\t# plot accuracy\n","\t\tpyplot.subplot(212)\n","\t\tpyplot.title('Classification Accuracy')\n","\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n","\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n","\tpyplot.show()\n","\n","# summarize model performance\n","def summarize_performance(scores):\n","\t# print summary\n","\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n","\t# box and whisker plots of results\n","\tpyplot.boxplot(scores)\n","\tpyplot.show()\n","\n","# run the test harness for evaluating a model\n","def run_test_harness():\n","\t# load dataset\n","\ttrainX, trainY, testX, testY = load_dataset()\n","\t# prepare pixel data\n","\ttrainX, testX = prep_pixels(trainX, testX)\n","\t# evaluate model\n","\tscores, histories = evaluate_model(trainX, trainY)\n","\t# learning curves\n","\tsummarize_diagnostics(histories)\n","\t# summarize estimated performance\n","\tsummarize_performance(scores)\n","\n","# entry point, run the test harness\n","run_test_harness()"],"execution_count":null,"outputs":[]}]}