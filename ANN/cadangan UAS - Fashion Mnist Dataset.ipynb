{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cadangan UAS - Fashion Mnist Dataset.ipynb","provenance":[{"file_id":"1qvK5jM5vX6nvhmAaQFMlPu0HF-JBBVW7","timestamp":1624462202853}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wxqNoA9ofhTa"},"source":["#UAS Daffa Rizki Rizaly - 2301931251\n","Fashion Mnist Dataset"]},{"cell_type":"markdown","metadata":{"id":"q84BqOLkSrnn"},"source":["## Import Library"]},{"cell_type":"code","metadata":{"id":"cIG0pGxae6w6"},"source":["import tensorflow as tf\n","from sklearn.decomposition import PCA\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools  \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7XJ-RC7PSw4l"},"source":["## Import Dataset"]},{"cell_type":"code","metadata":{"id":"rq_cdYhhguPv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626709323686,"user_tz":-420,"elapsed":1328,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"f4a823b8-42c2-4053-924c-ddb67e2020c0"},"source":["fashion_mnist = keras.datasets.fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B_DgEdo6S0Mq"},"source":["## Dataset Preprocessing"]},{"cell_type":"code","metadata":{"id":"0GL_TwTd3Asy"},"source":["classes = {0: 'T-shirt/top', \n","           1: 'Trouser', \n","           2: 'Pullover', \n","           3: 'Dress', \n","           4: 'Coat',\n","           5: 'Sandal', \n","           6: 'Shirt', \n","           7: 'Sneaker', \n","           8: 'Bag', \n","           9: 'Ankle boot'}\n","\n","class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat',\n","                       'Sandal','Shirt','Sneaker','Bag','Ankle boot']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-SpLPUd02wIl"},"source":["#Normalize Dataset\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fS-xIfGI3L9w"},"source":["# Split Dataset for Validation\n","X_train, X_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyGSzuJF4Pk2","executionInfo":{"status":"ok","timestamp":1626709325431,"user_tz":-420,"elapsed":13,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"01de442a-dd23-4583-8c36-e525c5e282b2"},"source":["image_rows = 28\n","image_cols = 28\n","input_shape = (image_rows, image_cols, 1)\n","\n","X_train = X_train.reshape(X_train.shape[0], image_rows, image_cols, 1)\n","X_test = x_test.reshape(x_test.shape[0], image_rows, image_cols, 1)\n","X_validate = X_validate.reshape(X_validate.shape[0], image_rows, image_cols, 1)\n","\n","print('x_train shape: {}'.format(X_train.shape))\n","print('x_test shape: {}'.format(X_test.shape))\n","print('x_validate shape: {}'.format(X_validate.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (48000, 28, 28, 1)\n","x_test shape: (10000, 28, 28, 1)\n","x_validate shape: (12000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QcnQOwUd4TZz"},"source":["# One-hot encoding\n","y_train = to_categorical(y_train, 10)\n","y_validate = to_categorical(y_validate, 10)\n","y_test = to_categorical(y_test, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nPc4DvzSZAaS"},"source":["## **Build the model**"]},{"cell_type":"markdown","metadata":{"id":"qwKqrmTHH12O"},"source":["##CNN - 1 Convolution layer\n"]},{"cell_type":"code","metadata":{"id":"wEf_2aY7FHhX"},"source":["cnn_model = Sequential()\n","\n","cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","\n","cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","cnn_model.add(Dropout(0.25))\n","\n","cnn_model.add(Flatten()) \n","\n","cnn_model.add(Dense(128, activation='relu'))\n","#dense = fully connected layer, fully connected layer mempunyai arti bahwa neuron di layer sebelumnya itu terhubung dengan neuron di layer selanjutnya. \n","\n","cnn_model.add(Dropout(0.2))\n","\n","cnn_model.add(Dense(10, activation='softmax'))\n","#softmax function biasanya digunakan di output layer di clustering algorithm, karena softmax ini merubah raw value menjadi sesuatu yang pasti. jumlah dari output probabilities di fully connected layer itu selalu 1."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoacLQXSFIyM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626709331071,"user_tz":-420,"elapsed":14,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"75fb4a1a-3176-48a9-8447-f0676176e1cb"},"source":["cnn_model.compile(optimizer= Adam(lr= 0.0001), # menggunakan adam karena adam paling cepat dan paling bagus\n","          loss='categorical_crossentropy',#categorical cross entropy mengukur performance dari model berdasarkan output yang berada di anta 0 dan 1. loss bertambah jika predicted probability melenceng dari label\n","          metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz2tzzYPFKFd","executionInfo":{"status":"ok","timestamp":1626709331072,"user_tz":-420,"elapsed":12,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"569eddc5-e7eb-4ca3-d1ce-94951b0f4bb2"},"source":["cnn_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 5408)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               692352    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 693,962\n","Trainable params: 693,962\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dT6vkUwnF7Bq","executionInfo":{"status":"ok","timestamp":1626709473993,"user_tz":-420,"elapsed":142927,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"76f464ec-9ec1-4576-e5f9-85a5f4405a72"},"source":["#fitting train data dengan validate, untuk menghindari overfit\n","history = cnn_model.fit(X_train, y_train,\n","          batch_size=300,\n","          epochs=75,\n","          verbose=1,\n","          validation_data=(X_validate, y_validate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/75\n","160/160 [==============================] - 32s 7ms/step - loss: 1.2414 - accuracy: 0.6501 - val_loss: 0.6791 - val_accuracy: 0.7801\n","Epoch 2/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.6310 - accuracy: 0.7822 - val_loss: 0.5279 - val_accuracy: 0.8200\n","Epoch 3/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.5304 - accuracy: 0.8139 - val_loss: 0.4641 - val_accuracy: 0.8415\n","Epoch 4/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4769 - accuracy: 0.8338 - val_loss: 0.4256 - val_accuracy: 0.8513\n","Epoch 5/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4426 - accuracy: 0.8453 - val_loss: 0.3996 - val_accuracy: 0.8598\n","Epoch 6/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4176 - accuracy: 0.8539 - val_loss: 0.3814 - val_accuracy: 0.8661\n","Epoch 7/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.8591 - val_loss: 0.3648 - val_accuracy: 0.8724\n","Epoch 8/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3847 - accuracy: 0.8649 - val_loss: 0.3534 - val_accuracy: 0.8749\n","Epoch 9/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3699 - accuracy: 0.8699 - val_loss: 0.3454 - val_accuracy: 0.8765\n","Epoch 10/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3600 - accuracy: 0.8737 - val_loss: 0.3329 - val_accuracy: 0.8806\n","Epoch 11/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3509 - accuracy: 0.8767 - val_loss: 0.3267 - val_accuracy: 0.8826\n","Epoch 12/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3411 - accuracy: 0.8798 - val_loss: 0.3222 - val_accuracy: 0.8832\n","Epoch 13/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3330 - accuracy: 0.8838 - val_loss: 0.3150 - val_accuracy: 0.8866\n","Epoch 14/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3279 - accuracy: 0.8831 - val_loss: 0.3085 - val_accuracy: 0.8882\n","Epoch 15/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3209 - accuracy: 0.8848 - val_loss: 0.3044 - val_accuracy: 0.8900\n","Epoch 16/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3134 - accuracy: 0.8897 - val_loss: 0.3016 - val_accuracy: 0.8901\n","Epoch 17/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3121 - accuracy: 0.8895 - val_loss: 0.2972 - val_accuracy: 0.8925\n","Epoch 18/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3036 - accuracy: 0.8916 - val_loss: 0.2919 - val_accuracy: 0.8930\n","Epoch 19/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3020 - accuracy: 0.8917 - val_loss: 0.2906 - val_accuracy: 0.8940\n","Epoch 20/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2954 - accuracy: 0.8946 - val_loss: 0.2858 - val_accuracy: 0.8960\n","Epoch 21/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2901 - accuracy: 0.8971 - val_loss: 0.2841 - val_accuracy: 0.8961\n","Epoch 22/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2875 - accuracy: 0.8968 - val_loss: 0.2802 - val_accuracy: 0.8978\n","Epoch 23/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2834 - accuracy: 0.8987 - val_loss: 0.2796 - val_accuracy: 0.8961\n","Epoch 24/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2802 - accuracy: 0.9005 - val_loss: 0.2764 - val_accuracy: 0.8988\n","Epoch 25/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2766 - accuracy: 0.9018 - val_loss: 0.2732 - val_accuracy: 0.9013\n","Epoch 26/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2753 - accuracy: 0.9020 - val_loss: 0.2719 - val_accuracy: 0.9007\n","Epoch 27/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2701 - accuracy: 0.9031 - val_loss: 0.2695 - val_accuracy: 0.8997\n","Epoch 28/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2668 - accuracy: 0.9057 - val_loss: 0.2665 - val_accuracy: 0.9026\n","Epoch 29/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2638 - accuracy: 0.9057 - val_loss: 0.2664 - val_accuracy: 0.9012\n","Epoch 30/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2592 - accuracy: 0.9073 - val_loss: 0.2625 - val_accuracy: 0.9043\n","Epoch 31/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2576 - accuracy: 0.9083 - val_loss: 0.2612 - val_accuracy: 0.9043\n","Epoch 32/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2571 - accuracy: 0.9082 - val_loss: 0.2600 - val_accuracy: 0.9048\n","Epoch 33/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2534 - accuracy: 0.9092 - val_loss: 0.2579 - val_accuracy: 0.9047\n","Epoch 34/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2498 - accuracy: 0.9110 - val_loss: 0.2558 - val_accuracy: 0.9058\n","Epoch 35/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2478 - accuracy: 0.9107 - val_loss: 0.2558 - val_accuracy: 0.9055\n","Epoch 36/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2446 - accuracy: 0.9126 - val_loss: 0.2542 - val_accuracy: 0.9056\n","Epoch 37/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2434 - accuracy: 0.9120 - val_loss: 0.2528 - val_accuracy: 0.9082\n","Epoch 38/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2403 - accuracy: 0.9137 - val_loss: 0.2579 - val_accuracy: 0.9049\n","Epoch 39/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2394 - accuracy: 0.9142 - val_loss: 0.2523 - val_accuracy: 0.9067\n","Epoch 40/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2361 - accuracy: 0.9153 - val_loss: 0.2496 - val_accuracy: 0.9103\n","Epoch 41/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2353 - accuracy: 0.9141 - val_loss: 0.2461 - val_accuracy: 0.9096\n","Epoch 42/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2321 - accuracy: 0.9161 - val_loss: 0.2487 - val_accuracy: 0.9071\n","Epoch 43/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2287 - accuracy: 0.9185 - val_loss: 0.2435 - val_accuracy: 0.9094\n","Epoch 44/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2280 - accuracy: 0.9174 - val_loss: 0.2423 - val_accuracy: 0.9109\n","Epoch 45/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2245 - accuracy: 0.9184 - val_loss: 0.2413 - val_accuracy: 0.9108\n","Epoch 46/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2254 - accuracy: 0.9182 - val_loss: 0.2401 - val_accuracy: 0.9119\n","Epoch 47/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2223 - accuracy: 0.9209 - val_loss: 0.2391 - val_accuracy: 0.9137\n","Epoch 48/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2196 - accuracy: 0.9205 - val_loss: 0.2394 - val_accuracy: 0.9125\n","Epoch 49/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2188 - accuracy: 0.9208 - val_loss: 0.2374 - val_accuracy: 0.9133\n","Epoch 50/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2161 - accuracy: 0.9209 - val_loss: 0.2382 - val_accuracy: 0.9118\n","Epoch 51/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2135 - accuracy: 0.9235 - val_loss: 0.2365 - val_accuracy: 0.9136\n","Epoch 52/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9235 - val_loss: 0.2336 - val_accuracy: 0.9146\n","Epoch 53/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2116 - accuracy: 0.9233 - val_loss: 0.2341 - val_accuracy: 0.9149\n","Epoch 54/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2075 - accuracy: 0.9262 - val_loss: 0.2359 - val_accuracy: 0.9135\n","Epoch 55/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2070 - accuracy: 0.9261 - val_loss: 0.2316 - val_accuracy: 0.9153\n","Epoch 56/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2068 - accuracy: 0.9251 - val_loss: 0.2316 - val_accuracy: 0.9159\n","Epoch 57/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9270 - val_loss: 0.2315 - val_accuracy: 0.9153\n","Epoch 58/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9279 - val_loss: 0.2311 - val_accuracy: 0.9169\n","Epoch 59/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2005 - accuracy: 0.9279 - val_loss: 0.2324 - val_accuracy: 0.9164\n","Epoch 60/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1994 - accuracy: 0.9283 - val_loss: 0.2280 - val_accuracy: 0.9165\n","Epoch 61/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9295 - val_loss: 0.2273 - val_accuracy: 0.9175\n","Epoch 62/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1971 - accuracy: 0.9298 - val_loss: 0.2303 - val_accuracy: 0.9170\n","Epoch 63/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1955 - accuracy: 0.9278 - val_loss: 0.2261 - val_accuracy: 0.9172\n","Epoch 64/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1942 - accuracy: 0.9285 - val_loss: 0.2259 - val_accuracy: 0.9175\n","Epoch 65/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1915 - accuracy: 0.9312 - val_loss: 0.2264 - val_accuracy: 0.9168\n","Epoch 66/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1884 - accuracy: 0.9317 - val_loss: 0.2239 - val_accuracy: 0.9183\n","Epoch 67/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1891 - accuracy: 0.9314 - val_loss: 0.2240 - val_accuracy: 0.9183\n","Epoch 68/75\n","160/160 [==============================] - 1s 7ms/step - loss: 0.1884 - accuracy: 0.9323 - val_loss: 0.2242 - val_accuracy: 0.9176\n","Epoch 69/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1865 - accuracy: 0.9341 - val_loss: 0.2237 - val_accuracy: 0.9194\n","Epoch 70/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1850 - accuracy: 0.9333 - val_loss: 0.2240 - val_accuracy: 0.9178\n","Epoch 71/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9345 - val_loss: 0.2225 - val_accuracy: 0.9203\n","Epoch 72/75\n","160/160 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9352 - val_loss: 0.2200 - val_accuracy: 0.9198\n","Epoch 73/75\n","160/160 [==============================] - 1s 7ms/step - loss: 0.1800 - accuracy: 0.9360 - val_loss: 0.2202 - val_accuracy: 0.9197\n","Epoch 74/75\n","160/160 [==============================] - 1s 7ms/step - loss: 0.1801 - accuracy: 0.9350 - val_loss: 0.2213 - val_accuracy: 0.9197\n","Epoch 75/75\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9356 - val_loss: 0.2207 - val_accuracy: 0.9193\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-jA0GXufGA_j","executionInfo":{"status":"ok","timestamp":1626709474603,"user_tz":-420,"elapsed":617,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"33a493de-e6db-434b-d3aa-7bb87509d021"},"source":["score = cnn_model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 0.2374357432126999\n","Test accuracy: 91.28000140190125\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KtuRl30ANICL"},"source":["## CNN - 2 Convolution layer\n"]},{"cell_type":"code","metadata":{"id":"A6QkrTbiHax5"},"source":["cnn_model_2 = Sequential()\n","\n","cnn_model_2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","#ada 32 filter, dengan 1 filternya berukuran 3*3, karena 3*3 bisa menangkap detail image yang lebih bagus dibanding 5*5, dan keperluan nkomputasi 3*3 lebih kecill dibanding 5*5. memilih relu sebagai activation function karena relu adalah default nya.\n","\n","cnn_model_2.add(Dropout(0.2))\n","#dropout untuk randomly shutdown neuron because kalau neuron udah kebanyakan biasnya itu isinya mirip atau bahakan sama, jadinya dengan randomly shutdown neuron, kita bisa percepat learning dan hemat computer power.\n","\n","cnn_model_2.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","#ada 64 filter, dengan 1 filternya berukuran 3*3, karena 3*3 bisa menangkap detail image yang lebih bagus dibanding 5*5, dan keperluan nkomputasi 3*3 lebih kecill dibanding 5*5. memilih relu sebagai activation function karena relu adalah default nya.\n","#karena namanya CNN 2 ya artinya jadi ada 2 layer cnn nya deh\n","\n","cnn_model_2.add(MaxPooling2D(pool_size=(2, 2)))\n","#pooling mengurangi dimensionality dari featured map tapi tetap mempertahankan informasi yang ada di dalamnya, pooling digunakan untuk mempercepat prose training, dan menghindari overfit.\n","\n","\n","cnn_model_2.add(Dropout(0.3))\n","cnn_model_2.add(Flatten())\n","#flatten adalah proses untuk mengubah data dari 2d array ke vector.\n","\n","\n","cnn_model_2.add(Dense(64, activation='relu'))\n","#dense = fully connected layer, fully connected layer mempunyai arti bahwa neuron di layer sebelumnya itu terhubung dengan neuron di layer selanjutnya. \n","cnn_model_2.add(Dense(128, activation='relu'))\n","#dense ada 2 karena namanya CNN 2layer jadinya ada 2 layer ya dense nya harus ditambahin juga\n","\n","cnn_model_2.add(Dense(10, activation='softmax'))\n","#softmax function biasanya digunakan di output layer di clustering algorithm, karena softmax ini merubah raw value menjadi sesuatu yang pasti. jumlah dari output probabilities di fully connected layer itu selalu 1."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sc79X5AVHdEM","executionInfo":{"status":"ok","timestamp":1626709475423,"user_tz":-420,"elapsed":54,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"6d61d962-c1e0-49c5-881e-7f0bb5981b4a"},"source":["cnn_model_2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 9216)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                589888    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               8320      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 618,314\n","Trainable params: 618,314\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dOZDtMZBHehS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626709475424,"user_tz":-420,"elapsed":48,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"49a11306-f883-46f1-e21d-ad42a3d06f0c"},"source":["cnn_model_2.compile(optimizer= Adam(lr= 0.0001),\n","          loss='categorical_crossentropy',\n","          metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0D-UbEgHhav","executionInfo":{"status":"ok","timestamp":1626709670326,"user_tz":-420,"elapsed":194944,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"e9a34552-90e6-4bd3-b706-a0e5a9be6e95"},"source":["history_2 = cnn_model_2.fit(X_train, y_train,\n","          batch_size= 300,\n","          epochs=75,\n","          verbose=1,\n","          validation_data=(X_validate, y_validate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/75\n","160/160 [==============================] - 4s 18ms/step - loss: 1.2033 - accuracy: 0.6152 - val_loss: 0.6591 - val_accuracy: 0.7616\n","Epoch 2/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.5848 - accuracy: 0.7879 - val_loss: 0.5285 - val_accuracy: 0.8097\n","Epoch 3/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.5046 - accuracy: 0.8178 - val_loss: 0.4892 - val_accuracy: 0.8211\n","Epoch 4/75\n","160/160 [==============================] - 2s 16ms/step - loss: 0.4618 - accuracy: 0.8351 - val_loss: 0.4381 - val_accuracy: 0.8477\n","Epoch 5/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.4331 - accuracy: 0.8466 - val_loss: 0.4096 - val_accuracy: 0.8542\n","Epoch 6/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.4147 - accuracy: 0.8537 - val_loss: 0.3946 - val_accuracy: 0.8600\n","Epoch 7/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.3972 - accuracy: 0.8606 - val_loss: 0.3796 - val_accuracy: 0.8670\n","Epoch 8/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.3828 - accuracy: 0.8650 - val_loss: 0.3724 - val_accuracy: 0.8687\n","Epoch 9/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.3729 - accuracy: 0.8676 - val_loss: 0.3527 - val_accuracy: 0.8736\n","Epoch 10/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3578 - accuracy: 0.8744 - val_loss: 0.3482 - val_accuracy: 0.8761\n","Epoch 11/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3489 - accuracy: 0.8750 - val_loss: 0.3358 - val_accuracy: 0.8807\n","Epoch 12/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3393 - accuracy: 0.8787 - val_loss: 0.3334 - val_accuracy: 0.8817\n","Epoch 13/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3304 - accuracy: 0.8821 - val_loss: 0.3224 - val_accuracy: 0.8847\n","Epoch 14/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.3261 - accuracy: 0.8832 - val_loss: 0.3211 - val_accuracy: 0.8838\n","Epoch 15/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3173 - accuracy: 0.8875 - val_loss: 0.3113 - val_accuracy: 0.8857\n","Epoch 16/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3102 - accuracy: 0.8889 - val_loss: 0.3036 - val_accuracy: 0.8883\n","Epoch 17/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.3033 - accuracy: 0.8903 - val_loss: 0.2984 - val_accuracy: 0.8898\n","Epoch 18/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.3009 - accuracy: 0.8907 - val_loss: 0.3027 - val_accuracy: 0.8890\n","Epoch 19/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2942 - accuracy: 0.8936 - val_loss: 0.2902 - val_accuracy: 0.8960\n","Epoch 20/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2881 - accuracy: 0.8957 - val_loss: 0.2876 - val_accuracy: 0.8958\n","Epoch 21/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2834 - accuracy: 0.8968 - val_loss: 0.2833 - val_accuracy: 0.8954\n","Epoch 22/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2776 - accuracy: 0.8995 - val_loss: 0.2862 - val_accuracy: 0.8944\n","Epoch 23/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2745 - accuracy: 0.9012 - val_loss: 0.2832 - val_accuracy: 0.8962\n","Epoch 24/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2682 - accuracy: 0.9033 - val_loss: 0.2745 - val_accuracy: 0.9036\n","Epoch 25/75\n","160/160 [==============================] - 2s 16ms/step - loss: 0.2647 - accuracy: 0.9043 - val_loss: 0.2755 - val_accuracy: 0.9000\n","Epoch 26/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2589 - accuracy: 0.9055 - val_loss: 0.2725 - val_accuracy: 0.8995\n","Epoch 27/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2574 - accuracy: 0.9066 - val_loss: 0.2663 - val_accuracy: 0.9025\n","Epoch 28/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2527 - accuracy: 0.9082 - val_loss: 0.2755 - val_accuracy: 0.8986\n","Epoch 29/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2490 - accuracy: 0.9093 - val_loss: 0.2637 - val_accuracy: 0.9053\n","Epoch 30/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2450 - accuracy: 0.9104 - val_loss: 0.2669 - val_accuracy: 0.9039\n","Epoch 31/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2445 - accuracy: 0.9097 - val_loss: 0.2624 - val_accuracy: 0.9043\n","Epoch 32/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2373 - accuracy: 0.9135 - val_loss: 0.2607 - val_accuracy: 0.9051\n","Epoch 33/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2363 - accuracy: 0.9148 - val_loss: 0.2654 - val_accuracy: 0.9031\n","Epoch 34/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2311 - accuracy: 0.9166 - val_loss: 0.2532 - val_accuracy: 0.9075\n","Epoch 35/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2288 - accuracy: 0.9156 - val_loss: 0.2533 - val_accuracy: 0.9070\n","Epoch 36/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2251 - accuracy: 0.9185 - val_loss: 0.2488 - val_accuracy: 0.9097\n","Epoch 37/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2214 - accuracy: 0.9186 - val_loss: 0.2462 - val_accuracy: 0.9105\n","Epoch 38/75\n","160/160 [==============================] - 2s 16ms/step - loss: 0.2195 - accuracy: 0.9211 - val_loss: 0.2454 - val_accuracy: 0.9107\n","Epoch 39/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2148 - accuracy: 0.9212 - val_loss: 0.2425 - val_accuracy: 0.9129\n","Epoch 40/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.2138 - accuracy: 0.9219 - val_loss: 0.2410 - val_accuracy: 0.9121\n","Epoch 41/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2097 - accuracy: 0.9240 - val_loss: 0.2416 - val_accuracy: 0.9121\n","Epoch 42/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2075 - accuracy: 0.9251 - val_loss: 0.2475 - val_accuracy: 0.9102\n","Epoch 43/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.2049 - accuracy: 0.9251 - val_loss: 0.2381 - val_accuracy: 0.9139\n","Epoch 44/75\n","160/160 [==============================] - 2s 16ms/step - loss: 0.2015 - accuracy: 0.9264 - val_loss: 0.2482 - val_accuracy: 0.9085\n","Epoch 45/75\n","160/160 [==============================] - 2s 16ms/step - loss: 0.1997 - accuracy: 0.9268 - val_loss: 0.2351 - val_accuracy: 0.9159\n","Epoch 46/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1975 - accuracy: 0.9280 - val_loss: 0.2357 - val_accuracy: 0.9145\n","Epoch 47/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1941 - accuracy: 0.9289 - val_loss: 0.2365 - val_accuracy: 0.9141\n","Epoch 48/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1911 - accuracy: 0.9308 - val_loss: 0.2349 - val_accuracy: 0.9162\n","Epoch 49/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1887 - accuracy: 0.9310 - val_loss: 0.2321 - val_accuracy: 0.9181\n","Epoch 50/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1872 - accuracy: 0.9306 - val_loss: 0.2309 - val_accuracy: 0.9162\n","Epoch 51/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1837 - accuracy: 0.9330 - val_loss: 0.2299 - val_accuracy: 0.9175\n","Epoch 52/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1826 - accuracy: 0.9337 - val_loss: 0.2281 - val_accuracy: 0.9183\n","Epoch 53/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1789 - accuracy: 0.9352 - val_loss: 0.2323 - val_accuracy: 0.9147\n","Epoch 54/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1784 - accuracy: 0.9342 - val_loss: 0.2317 - val_accuracy: 0.9168\n","Epoch 55/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1749 - accuracy: 0.9358 - val_loss: 0.2294 - val_accuracy: 0.9196\n","Epoch 56/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1746 - accuracy: 0.9364 - val_loss: 0.2230 - val_accuracy: 0.9196\n","Epoch 57/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1705 - accuracy: 0.9375 - val_loss: 0.2241 - val_accuracy: 0.9183\n","Epoch 58/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1670 - accuracy: 0.9391 - val_loss: 0.2294 - val_accuracy: 0.9179\n","Epoch 59/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1677 - accuracy: 0.9383 - val_loss: 0.2248 - val_accuracy: 0.9193\n","Epoch 60/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1634 - accuracy: 0.9404 - val_loss: 0.2236 - val_accuracy: 0.9214\n","Epoch 61/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1616 - accuracy: 0.9417 - val_loss: 0.2338 - val_accuracy: 0.9155\n","Epoch 62/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1597 - accuracy: 0.9421 - val_loss: 0.2264 - val_accuracy: 0.9202\n","Epoch 63/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1596 - accuracy: 0.9408 - val_loss: 0.2318 - val_accuracy: 0.9178\n","Epoch 64/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1568 - accuracy: 0.9426 - val_loss: 0.2247 - val_accuracy: 0.9205\n","Epoch 65/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1542 - accuracy: 0.9431 - val_loss: 0.2228 - val_accuracy: 0.9217\n","Epoch 66/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1509 - accuracy: 0.9454 - val_loss: 0.2249 - val_accuracy: 0.9209\n","Epoch 67/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1496 - accuracy: 0.9459 - val_loss: 0.2240 - val_accuracy: 0.9223\n","Epoch 68/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1479 - accuracy: 0.9461 - val_loss: 0.2246 - val_accuracy: 0.9216\n","Epoch 69/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1466 - accuracy: 0.9467 - val_loss: 0.2283 - val_accuracy: 0.9202\n","Epoch 70/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1426 - accuracy: 0.9470 - val_loss: 0.2204 - val_accuracy: 0.9224\n","Epoch 71/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1442 - accuracy: 0.9474 - val_loss: 0.2228 - val_accuracy: 0.9226\n","Epoch 72/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1406 - accuracy: 0.9482 - val_loss: 0.2253 - val_accuracy: 0.9243\n","Epoch 73/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1389 - accuracy: 0.9494 - val_loss: 0.2222 - val_accuracy: 0.9203\n","Epoch 74/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1374 - accuracy: 0.9499 - val_loss: 0.2180 - val_accuracy: 0.9247\n","Epoch 75/75\n","160/160 [==============================] - 3s 16ms/step - loss: 0.1361 - accuracy: 0.9504 - val_loss: 0.2222 - val_accuracy: 0.9241\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPxd-tytHjbI","executionInfo":{"status":"ok","timestamp":1626709671594,"user_tz":-420,"elapsed":1282,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"7b3f9f56-d196-443a-bab3-cb79cf8ac6c3"},"source":["score = cnn_model_2.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 0.23621542751789093\n","Test accuracy: 91.7900025844574\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"59TrcmnINMUb"},"source":["## CNN - 3 Convolution layer\n"]},{"cell_type":"code","metadata":{"id":"ZFgpktJGHmOH"},"source":["cnn_model_3 = Sequential() #It allows us to create a deep learning model by adding layers to it. Here, every unit in a layer is connected to every unit in the previous layer. \n","\n","cnn_model_3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","#ada 32 filter, dengan 1 filternya berukuran 3*3, karena 3*3 bisa menangkap detail image yang lebih bagus dibanding 5*5, dan keperluan nkomputasi 3*3 lebih kecill dibanding 5*5. memilih relu sebagai activation function karena relu adalah default nya.\n","cnn_model_3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","#ada 64 filter, dengan 1 filternya berukuran 3*3, karena 3*3 bisa menangkap detail image yang lebih bagus dibanding 5*5, dan keperluan nkomputasi 3*3 lebih kecill dibanding 5*5. memilih relu sebagai activation function karena relu adalah default nya.\n","#karena namanya CNN 3 ya artinya jadi ada 3 layer cnn nya deh\n","cnn_model_3.add(MaxPooling2D(pool_size=(2, 2)))\n","#pooling mengurangi dimensionality dari featured map tapi tetap mempertahankan informasi yang ada di dalamnya, pooling digunakan untuk mempercepat prose training, dan menghindari overfit.\n","cnn_model_3.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","#ada 128 filter, dengan 1 filternya berukuran 3*3, karena 3*3 bisa menangkap detail image yang lebih bagus dibanding 5*5, dan keperluan nkomputasi 3*3 lebih kecill dibanding 5*5. memilih relu sebagai activation function karena relu adalah default nya.\n","#karena namanya CNN 3 ya artinya jadi ada 3 layer cnn nya deh\n","cnn_model_3.add(MaxPooling2D(pool_size=(2, 2)))\n","#pooling mengurangi dimensionality dari featured map tapi tetap mempertahankan informasi yang ada di dalamnya, pooling digunakan untuk mempercepat prose training, dan menghindari overfit.\n","\n","cnn_model_3.add(Dropout(0.3))#dropout untuk randomly shutdown neuron because kalau neuron udah kebanyakan biasnya itu isinya mirip atau bahakan sama, jadinya denga randomly shutdown neuron, kita bisa percepat learning dan hemat computer resources\n","cnn_model_3.add(Flatten()) #flattening untuk bisa dimasukkan ke NN\n","#flatten adalah proses untuk mengubah data dari 2d array ke vector.\n","\n","cnn_model_3.add(Dense(128, activation='relu'))\n","#dense = fully connected layer, fully connected layer mempunyai arti bahwa neuron di layer sebelumnya itu terhubung dengan neuron di layer selanjutnya. \n","\n","cnn_model_3.add(Dense(256, activation='relu'))\n","#dense = fully connected layer, fully connected layer mempunyai arti bahwa neuron di layer sebelumnya itu terhubung dengan neuron di layer selanjutnya. \n","\n","cnn_model_3.add(Dense(10, activation='softmax'))#softmax function is used to normalize the outputs, converting them from weighted sum values into probabilities that sum to one"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn-OC4fuHnlg","executionInfo":{"status":"ok","timestamp":1626709672583,"user_tz":-420,"elapsed":28,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"d4ef3108-8804-46b1-dbd8-bbb9727d113b"},"source":["cnn_model_3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 10, 10, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 3200)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               409728    \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 537,994\n","Trainable params: 537,994\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kSZsfs9uHo6o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626709672583,"user_tz":-420,"elapsed":24,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"c85d7adc-ce1d-4f1c-cc41-fb7b2fbccef7"},"source":["cnn_model_3.compile(optimizer= Adam(lr= 0.0001),#adam optimizer emang yang paling prefferd because it is computationally efficient, and Adam works well in cases in large datasets and large parameter settings.\n","          loss='categorical_crossentropy', #Categorical crossentropy is a loss function that is used in multi-class classification tasks. These are tasks where an example can only belong to one out of many possible categories, and the model must decide which one.\n","          metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBIsw4X5HqtW","executionInfo":{"status":"ok","timestamp":1626709934871,"user_tz":-420,"elapsed":262310,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"4fe30b48-1418-4e36-b228-cc69ddd42ac6"},"source":["history_3 = cnn_model_3.fit(X_train, y_train,\n","                            batch_size=300,\n","                            epochs=75,\n","                            verbose=1, #hanya untuk visualisasi epoch\n","                            validation_data=(X_validate, y_validate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/75\n","160/160 [==============================] - 4s 19ms/step - loss: 1.1878 - accuracy: 0.6034 - val_loss: 0.6654 - val_accuracy: 0.7471\n","Epoch 2/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.6170 - accuracy: 0.7646 - val_loss: 0.5319 - val_accuracy: 0.7970\n","Epoch 3/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.5276 - accuracy: 0.8021 - val_loss: 0.4770 - val_accuracy: 0.8220\n","Epoch 4/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.4827 - accuracy: 0.8213 - val_loss: 0.4403 - val_accuracy: 0.8422\n","Epoch 5/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.4495 - accuracy: 0.8371 - val_loss: 0.4145 - val_accuracy: 0.8532\n","Epoch 6/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.4251 - accuracy: 0.8478 - val_loss: 0.3986 - val_accuracy: 0.8571\n","Epoch 7/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3993 - accuracy: 0.8567 - val_loss: 0.3724 - val_accuracy: 0.8648\n","Epoch 8/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3810 - accuracy: 0.8637 - val_loss: 0.3604 - val_accuracy: 0.8694\n","Epoch 9/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3668 - accuracy: 0.8675 - val_loss: 0.3489 - val_accuracy: 0.8733\n","Epoch 10/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3506 - accuracy: 0.8732 - val_loss: 0.3423 - val_accuracy: 0.8759\n","Epoch 11/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3406 - accuracy: 0.8766 - val_loss: 0.3390 - val_accuracy: 0.8738\n","Epoch 12/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3308 - accuracy: 0.8809 - val_loss: 0.3168 - val_accuracy: 0.8823\n","Epoch 13/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3232 - accuracy: 0.8845 - val_loss: 0.3069 - val_accuracy: 0.8865\n","Epoch 14/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3125 - accuracy: 0.8882 - val_loss: 0.3027 - val_accuracy: 0.8896\n","Epoch 15/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3070 - accuracy: 0.8900 - val_loss: 0.2967 - val_accuracy: 0.8923\n","Epoch 16/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.3000 - accuracy: 0.8908 - val_loss: 0.3008 - val_accuracy: 0.8917\n","Epoch 17/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2913 - accuracy: 0.8936 - val_loss: 0.2857 - val_accuracy: 0.8965\n","Epoch 18/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2849 - accuracy: 0.8968 - val_loss: 0.2831 - val_accuracy: 0.8962\n","Epoch 19/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2795 - accuracy: 0.8995 - val_loss: 0.2875 - val_accuracy: 0.8966\n","Epoch 20/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2733 - accuracy: 0.9012 - val_loss: 0.2776 - val_accuracy: 0.8984\n","Epoch 21/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2673 - accuracy: 0.9039 - val_loss: 0.2724 - val_accuracy: 0.9001\n","Epoch 22/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2624 - accuracy: 0.9055 - val_loss: 0.2650 - val_accuracy: 0.9019\n","Epoch 23/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2550 - accuracy: 0.9067 - val_loss: 0.2658 - val_accuracy: 0.9013\n","Epoch 24/75\n","160/160 [==============================] - 3s 19ms/step - loss: 0.2537 - accuracy: 0.9073 - val_loss: 0.2658 - val_accuracy: 0.9057\n","Epoch 25/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2481 - accuracy: 0.9093 - val_loss: 0.2637 - val_accuracy: 0.9043\n","Epoch 26/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2394 - accuracy: 0.9134 - val_loss: 0.2659 - val_accuracy: 0.9032\n","Epoch 27/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2399 - accuracy: 0.9128 - val_loss: 0.2585 - val_accuracy: 0.9057\n","Epoch 28/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2347 - accuracy: 0.9146 - val_loss: 0.2502 - val_accuracy: 0.9074\n","Epoch 29/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2295 - accuracy: 0.9149 - val_loss: 0.2457 - val_accuracy: 0.9110\n","Epoch 30/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2243 - accuracy: 0.9186 - val_loss: 0.2425 - val_accuracy: 0.9112\n","Epoch 31/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2210 - accuracy: 0.9184 - val_loss: 0.2466 - val_accuracy: 0.9091\n","Epoch 32/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2186 - accuracy: 0.9210 - val_loss: 0.2469 - val_accuracy: 0.9082\n","Epoch 33/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2146 - accuracy: 0.9212 - val_loss: 0.2373 - val_accuracy: 0.9105\n","Epoch 34/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2120 - accuracy: 0.9219 - val_loss: 0.2359 - val_accuracy: 0.9138\n","Epoch 35/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2083 - accuracy: 0.9240 - val_loss: 0.2404 - val_accuracy: 0.9103\n","Epoch 36/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2047 - accuracy: 0.9252 - val_loss: 0.2320 - val_accuracy: 0.9158\n","Epoch 37/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.2010 - accuracy: 0.9267 - val_loss: 0.2286 - val_accuracy: 0.9155\n","Epoch 38/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1968 - accuracy: 0.9289 - val_loss: 0.2326 - val_accuracy: 0.9146\n","Epoch 39/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1924 - accuracy: 0.9293 - val_loss: 0.2269 - val_accuracy: 0.9169\n","Epoch 40/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1913 - accuracy: 0.9298 - val_loss: 0.2293 - val_accuracy: 0.9160\n","Epoch 41/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1869 - accuracy: 0.9309 - val_loss: 0.2349 - val_accuracy: 0.9157\n","Epoch 42/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1863 - accuracy: 0.9307 - val_loss: 0.2263 - val_accuracy: 0.9163\n","Epoch 43/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1829 - accuracy: 0.9325 - val_loss: 0.2265 - val_accuracy: 0.9165\n","Epoch 44/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1803 - accuracy: 0.9337 - val_loss: 0.2242 - val_accuracy: 0.9185\n","Epoch 45/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1758 - accuracy: 0.9354 - val_loss: 0.2237 - val_accuracy: 0.9192\n","Epoch 46/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1722 - accuracy: 0.9366 - val_loss: 0.2204 - val_accuracy: 0.9208\n","Epoch 47/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1715 - accuracy: 0.9372 - val_loss: 0.2216 - val_accuracy: 0.9191\n","Epoch 48/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1675 - accuracy: 0.9378 - val_loss: 0.2284 - val_accuracy: 0.9199\n","Epoch 49/75\n","160/160 [==============================] - 3s 19ms/step - loss: 0.1661 - accuracy: 0.9376 - val_loss: 0.2195 - val_accuracy: 0.9187\n","Epoch 50/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1615 - accuracy: 0.9408 - val_loss: 0.2259 - val_accuracy: 0.9200\n","Epoch 51/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1585 - accuracy: 0.9414 - val_loss: 0.2189 - val_accuracy: 0.9214\n","Epoch 52/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1573 - accuracy: 0.9423 - val_loss: 0.2214 - val_accuracy: 0.9202\n","Epoch 53/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1539 - accuracy: 0.9433 - val_loss: 0.2185 - val_accuracy: 0.9221\n","Epoch 54/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1514 - accuracy: 0.9442 - val_loss: 0.2218 - val_accuracy: 0.9196\n","Epoch 55/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1514 - accuracy: 0.9442 - val_loss: 0.2173 - val_accuracy: 0.9220\n","Epoch 56/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1487 - accuracy: 0.9447 - val_loss: 0.2186 - val_accuracy: 0.9215\n","Epoch 57/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1452 - accuracy: 0.9467 - val_loss: 0.2197 - val_accuracy: 0.9212\n","Epoch 58/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1426 - accuracy: 0.9481 - val_loss: 0.2238 - val_accuracy: 0.9199\n","Epoch 59/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1417 - accuracy: 0.9472 - val_loss: 0.2212 - val_accuracy: 0.9212\n","Epoch 60/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1377 - accuracy: 0.9490 - val_loss: 0.2177 - val_accuracy: 0.9236\n","Epoch 61/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1362 - accuracy: 0.9501 - val_loss: 0.2159 - val_accuracy: 0.9227\n","Epoch 62/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1353 - accuracy: 0.9496 - val_loss: 0.2169 - val_accuracy: 0.9232\n","Epoch 63/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1334 - accuracy: 0.9509 - val_loss: 0.2217 - val_accuracy: 0.9202\n","Epoch 64/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1281 - accuracy: 0.9520 - val_loss: 0.2169 - val_accuracy: 0.9239\n","Epoch 65/75\n","160/160 [==============================] - 3s 17ms/step - loss: 0.1268 - accuracy: 0.9532 - val_loss: 0.2170 - val_accuracy: 0.9246\n","Epoch 66/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1249 - accuracy: 0.9529 - val_loss: 0.2152 - val_accuracy: 0.9225\n","Epoch 67/75\n","160/160 [==============================] - 3s 19ms/step - loss: 0.1232 - accuracy: 0.9546 - val_loss: 0.2147 - val_accuracy: 0.9235\n","Epoch 68/75\n","160/160 [==============================] - 3s 19ms/step - loss: 0.1185 - accuracy: 0.9560 - val_loss: 0.2235 - val_accuracy: 0.9230\n","Epoch 69/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1186 - accuracy: 0.9549 - val_loss: 0.2212 - val_accuracy: 0.9246\n","Epoch 70/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1169 - accuracy: 0.9565 - val_loss: 0.2186 - val_accuracy: 0.9231\n","Epoch 71/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1158 - accuracy: 0.9565 - val_loss: 0.2185 - val_accuracy: 0.9249\n","Epoch 72/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1100 - accuracy: 0.9599 - val_loss: 0.2278 - val_accuracy: 0.9233\n","Epoch 73/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1129 - accuracy: 0.9578 - val_loss: 0.2212 - val_accuracy: 0.9227\n","Epoch 74/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1073 - accuracy: 0.9607 - val_loss: 0.2238 - val_accuracy: 0.9218\n","Epoch 75/75\n","160/160 [==============================] - 3s 18ms/step - loss: 0.1094 - accuracy: 0.9599 - val_loss: 0.2290 - val_accuracy: 0.9227\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QDbNdhgxHuVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626709936847,"user_tz":-420,"elapsed":1991,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"44e3f4d4-ac0b-4d85-ea0f-ade3beb7e4a9"},"source":["y_pred = cnn_model_3.predict_classes(X_test, verbose=0)\n","score = cnn_model_3.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Test loss: 0.24464048445224762\n","Test accuracy: 91.90000295639038\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sLmNU-sOpJud"},"source":["## Evaluation Matrix"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPgAWTgMrD_p","executionInfo":{"status":"ok","timestamp":1626713759057,"user_tz":-420,"elapsed":1629,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"582082fc-3acf-4d04-81cb-b9df686c6ac2"},"source":["test_loss, test_acc = cnn_model_3.evaluate(X_test, y_test)\n","print('Test accuracy:',test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9190\n","Test accuracy: 0.9190000295639038\n"],"name":"stdout"}]}]}