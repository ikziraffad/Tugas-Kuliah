{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_ANN_2301869840_William_Yulio.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"yKuU_dY3qGYk","outputId":"50f326e5-2759-4283-8770-a117d7d28f34"},"source":["import time\n","time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.localtime(105484586906))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Sat, 03 Sep 5312 10:08:26 +0000'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"tBpP_fa94QgG"},"source":["##Practical Example of BPNN\n","\n","credit: https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"]},{"cell_type":"code","metadata":{"id":"sUT9ftok3_EJ"},"source":["from random import seed\n","from random import random\n","\n","from math import exp\n","import numpy as np\n","import pandas as pd\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_HCckmV4Mgm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"748f277b-ec54-40f9-8cdf-b69493d450fd"},"source":[" # Initialize a network, and randomly assign the weights\n","def initialize_network(n_inputs, n_hidden, n_outputs):\n","\tnetwork = list()\n","\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n","\tnetwork.append(hidden_layer)\n","\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n","\tnetwork.append(output_layer)\n","\treturn network\n"," \n","seed(10)\n","network = initialize_network(2, 1, 1)\n","for layer in network:\n","\tprint(layer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'weights': [0.5714025946899135, 0.4288890546751146, 0.5780913011344704]}]\n","[{'weights': [0.20609823213950174, 0.81332125135732]}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"31Y2txqH5Ovs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b040842c-62ce-4e46-90c9-bc1d9dfdb1a3"},"source":["#manual assignment of weights\n","network = [[{'weights': [0.5, 0.1, 1]}],\n"," [{'weights': [1, -1]}]]\n","\n","network"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[{'weights': [0.5, 0.1, 1]}], [{'weights': [1, -1]}]]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"qGxblrC16HjF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"268ff6fc-7b76-4c6f-fb10-2ffffe8c3da7"},"source":["#Forward propagation\n","\n","\n","# Calculate neuron activation for an input\n","def activate(weights, inputs):\n","\tactivation = weights[-1]\n","\tfor i in range(len(weights)-1):\n","\t\tactivation += weights[i] * inputs[i]\n","\treturn activation\n","\n","# Transfer neuron activation\n","def transfer(activation):\n","\treturn np.round(1.0 / (1.0 + exp(-activation)),2)\n","\n","# Forward propagate input to a network output\n","def forward_propagate(network, row):\n","\tinputs = row\n","\tfor layer in network:\n","\t\tnew_inputs = []\n","\t\tfor neuron in layer:\n","\t\t\tactivation = activate(neuron['weights'], inputs) #linear combination\n","\t\t\tneuron['output'] = transfer(activation) # activation function e.g. sigmoid\n","\t\t\tnew_inputs.append(neuron['output'])\n","\t\tinputs = new_inputs\n","\treturn inputs\n","\n","# test forward propagation\n","row = [1, 2]\n","output = forward_propagate(network, row)\n","for layer in network:\n","\tprint(layer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'weights': [0.5, 0.1, 1], 'output': 0.85}]\n","[{'weights': [1, -1], 'output': 0.46}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WXXANPM07pSJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a34bcb07-7f8d-49ae-cf10-7966f8a5969e"},"source":["# Calculate the derivative of an neuron output\n","def transfer_derivative(output):\n","\treturn output * (1.0 - output)\n","\n","# Backpropagate error and store in neurons\n","def backward_propagate_error(network, expected):\n","\tfor i in reversed(range(len(network))):\n","\t\tlayer = network[i]\n","\t\terrors = list()\n","\t\tif i != len(network)-1:\n","\t\t\tfor j in range(len(layer)):\n","\t\t\t\terror = 0.0\n","\t\t\t\tfor neuron in network[i + 1]:\n","\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n","\t\t\t\terrors.append(error)\n","\t\telse:\n","\t\t\tfor j in range(len(layer)):\n","\t\t\t\tneuron = layer[j]\n","\t\t\t\terrors.append(expected[j] - neuron['output'])\n","\t\tfor j in range(len(layer)):\n","\t\t\tneuron = layer[j]\n","\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n","\n","# test backpropagation of error\n","\n","expected = [1]\n","backward_propagate_error(network, expected)\n","for layer in network:\n","\tprint(layer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'weights': [0.5, 0.1, 1], 'output': 0.85, 'delta': 0.017102340000000004}]\n","[{'weights': [1, -1], 'output': 0.46, 'delta': 0.13413600000000003}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"99fFL0AM_YPt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c6f8ecd-acf1-47b9-d4d4-b73ef8d89e4f"},"source":["# Update network weights with error\n","def update_weights(network, row, l_rate):\n","\tfor i in range(len(network)):\n","\t\tinputs = row[:-1]\n","\t\tif i != 0:\n","\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n","\t\tfor neuron in network[i]:\n","\t\t\tfor j in range(len(inputs)):\n","\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n","\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n","\n","\n","lr = 0.5\n","update_weights(network, row, lr)\n","\n","for layer in network:\n","\tprint(layer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'weights': [0.50855117, 0.1, 1.00855117], 'output': 0.85, 'delta': 0.017102340000000004}]\n","[{'weights': [1.0570078, -0.932932], 'output': 0.46, 'delta': 0.13413600000000003}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e2rgjgDa_tBw"},"source":["#Apply this function to learn from data - you must provide the train variable which consist of your dataset\n","\n","# Train a network for a fixed number of epochs\n","def train_network(network, train, l_rate, n_epoch, n_outputs, val):\n","  \n","  for epoch in range(n_epoch+1):\n","    sum_error = 0\n","    \n","    for row in train:  \n","      outputs = forward_propagate(network, row[:5])\n","      expected = row[4:5]\n","      sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n","      backward_propagate_error(network, expected)\n","      update_weights(network, row, l_rate)\n","    if epoch % 5 == 0:\n","       for row in val:  \n","         outputs = forward_propagate(network, row[:5])\n","         expected = row[4:5]\n","         sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n","         backward_propagate_error(network, expected)\n","         update_weights(network, row, l_rate)\n","      \n","       print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n","       \n","        \n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-N5ro_zkRRc","outputId":"56343fb8-77aa-41d5-cf24-b9d6f5569623"},"source":["# Test training backprop algorithm\n","seed(1)\n","\n","dataset = pd.read_csv('train.csv')\n","\n","dataset[[\"class\"]] = dataset[[\"class\"]].apply(lambda col:pd.Categorical(col).codes)\n","dataset = dataset.to_numpy().tolist()\n","\n","val = pd.read_csv('val.csv')\n","\n","val[[\"class\"]] = val[[\"class\"]].apply(lambda col:pd.Categorical(col).codes)\n","val = val.to_numpy().tolist()\n","\n","test = pd.read_csv('test.csv')\n","\n","test[[\"class\"]] = test[[\"class\"]].apply(lambda col:pd.Categorical(col).codes)\n","test = test.to_numpy().tolist()\n","\n","\n","\n","# dataset = [[2.7810836,2.550537003,0],\n","# \t[1.465489372,2.362125076,0],\n","# \t[3.396561688,4.400293529,0],\n","# \t[1.38807019,1.850220317,0],\n","# \t[3.06407232,3.005305973,0],\n","# \t[7.627531214,2.759262235,1],\n","# \t[5.332441248,2.088626775,1],\n","# \t[6.922596716,1.77106367,1],\n","# \t[8.675418651,-0.242068655,1],\n","# \t[7.673756466,3.508563011,1]]\n","\n","\n","n_inputs = len(dataset[0]) - 1\n","n_hidden = 1\n","n_outputs = 1\n","network = initialize_network(n_inputs, n_hidden, n_outputs)\n","\n","\n","#use it if you want to determine initial weights:\n","# network = [[{'weights': [0.5, 0.1, 1]}],\n","#            [{'weights': [1, -1]}]]\n","\n","epoch = 1000\n","lr = 0.5\n","train_network(network, dataset, lr, epoch, n_outputs, val)\n","# for layer in network:\n","# \tprint(layer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[">epoch=0, lrate=0.500, error=10.563\n",">epoch=5, lrate=0.500, error=10.185\n",">epoch=10, lrate=0.500, error=10.171\n",">epoch=15, lrate=0.500, error=10.203\n",">epoch=20, lrate=0.500, error=10.203\n",">epoch=25, lrate=0.500, error=10.197\n",">epoch=30, lrate=0.500, error=10.197\n",">epoch=35, lrate=0.500, error=10.172\n",">epoch=40, lrate=0.500, error=10.185\n",">epoch=45, lrate=0.500, error=10.192\n",">epoch=50, lrate=0.500, error=10.191\n",">epoch=55, lrate=0.500, error=10.174\n",">epoch=60, lrate=0.500, error=8.644\n",">epoch=65, lrate=0.500, error=3.305\n",">epoch=70, lrate=0.500, error=1.407\n",">epoch=75, lrate=0.500, error=0.810\n",">epoch=80, lrate=0.500, error=0.552\n",">epoch=85, lrate=0.500, error=0.416\n",">epoch=90, lrate=0.500, error=0.321\n",">epoch=95, lrate=0.500, error=0.274\n",">epoch=100, lrate=0.500, error=0.223\n",">epoch=105, lrate=0.500, error=0.200\n",">epoch=110, lrate=0.500, error=0.169\n",">epoch=115, lrate=0.500, error=0.154\n",">epoch=120, lrate=0.500, error=0.139\n",">epoch=125, lrate=0.500, error=0.138\n",">epoch=130, lrate=0.500, error=0.120\n",">epoch=135, lrate=0.500, error=0.108\n",">epoch=140, lrate=0.500, error=0.095\n",">epoch=145, lrate=0.500, error=0.095\n",">epoch=150, lrate=0.500, error=0.089\n",">epoch=155, lrate=0.500, error=0.087\n",">epoch=160, lrate=0.500, error=0.082\n",">epoch=165, lrate=0.500, error=0.077\n",">epoch=170, lrate=0.500, error=0.075\n",">epoch=175, lrate=0.500, error=0.062\n",">epoch=180, lrate=0.500, error=0.059\n",">epoch=185, lrate=0.500, error=0.059\n",">epoch=190, lrate=0.500, error=0.053\n",">epoch=195, lrate=0.500, error=0.053\n",">epoch=200, lrate=0.500, error=0.053\n",">epoch=205, lrate=0.500, error=0.053\n",">epoch=210, lrate=0.500, error=0.052\n",">epoch=215, lrate=0.500, error=0.051\n",">epoch=220, lrate=0.500, error=0.051\n",">epoch=225, lrate=0.500, error=0.050\n",">epoch=230, lrate=0.500, error=0.049\n",">epoch=235, lrate=0.500, error=0.049\n",">epoch=240, lrate=0.500, error=0.047\n",">epoch=245, lrate=0.500, error=0.039\n",">epoch=250, lrate=0.500, error=0.035\n",">epoch=255, lrate=0.500, error=0.034\n",">epoch=260, lrate=0.500, error=0.034\n",">epoch=265, lrate=0.500, error=0.033\n",">epoch=270, lrate=0.500, error=0.031\n",">epoch=275, lrate=0.500, error=0.030\n",">epoch=280, lrate=0.500, error=0.030\n",">epoch=285, lrate=0.500, error=0.028\n",">epoch=290, lrate=0.500, error=0.028\n",">epoch=295, lrate=0.500, error=0.028\n",">epoch=300, lrate=0.500, error=0.028\n",">epoch=305, lrate=0.500, error=0.028\n",">epoch=310, lrate=0.500, error=0.028\n",">epoch=315, lrate=0.500, error=0.028\n",">epoch=320, lrate=0.500, error=0.028\n",">epoch=325, lrate=0.500, error=0.028\n",">epoch=330, lrate=0.500, error=0.028\n",">epoch=335, lrate=0.500, error=0.027\n",">epoch=340, lrate=0.500, error=0.027\n",">epoch=345, lrate=0.500, error=0.026\n",">epoch=350, lrate=0.500, error=0.026\n",">epoch=355, lrate=0.500, error=0.024\n",">epoch=360, lrate=0.500, error=0.024\n",">epoch=365, lrate=0.500, error=0.024\n",">epoch=370, lrate=0.500, error=0.024\n",">epoch=375, lrate=0.500, error=0.024\n",">epoch=380, lrate=0.500, error=0.024\n",">epoch=385, lrate=0.500, error=0.024\n",">epoch=390, lrate=0.500, error=0.019\n",">epoch=395, lrate=0.500, error=0.019\n",">epoch=400, lrate=0.500, error=0.019\n",">epoch=405, lrate=0.500, error=0.019\n",">epoch=410, lrate=0.500, error=0.019\n",">epoch=415, lrate=0.500, error=0.019\n",">epoch=420, lrate=0.500, error=0.019\n",">epoch=425, lrate=0.500, error=0.019\n",">epoch=430, lrate=0.500, error=0.019\n",">epoch=435, lrate=0.500, error=0.019\n",">epoch=440, lrate=0.500, error=0.019\n",">epoch=445, lrate=0.500, error=0.019\n",">epoch=450, lrate=0.500, error=0.019\n",">epoch=455, lrate=0.500, error=0.019\n",">epoch=460, lrate=0.500, error=0.019\n",">epoch=465, lrate=0.500, error=0.019\n",">epoch=470, lrate=0.500, error=0.019\n",">epoch=475, lrate=0.500, error=0.018\n",">epoch=480, lrate=0.500, error=0.018\n",">epoch=485, lrate=0.500, error=0.018\n",">epoch=490, lrate=0.500, error=0.018\n",">epoch=495, lrate=0.500, error=0.018\n",">epoch=500, lrate=0.500, error=0.015\n",">epoch=505, lrate=0.500, error=0.015\n",">epoch=510, lrate=0.500, error=0.014\n",">epoch=515, lrate=0.500, error=0.012\n",">epoch=520, lrate=0.500, error=0.012\n",">epoch=525, lrate=0.500, error=0.012\n",">epoch=530, lrate=0.500, error=0.012\n",">epoch=535, lrate=0.500, error=0.012\n",">epoch=540, lrate=0.500, error=0.012\n",">epoch=545, lrate=0.500, error=0.012\n",">epoch=550, lrate=0.500, error=0.012\n",">epoch=555, lrate=0.500, error=0.012\n",">epoch=560, lrate=0.500, error=0.012\n",">epoch=565, lrate=0.500, error=0.012\n",">epoch=570, lrate=0.500, error=0.012\n",">epoch=575, lrate=0.500, error=0.011\n",">epoch=580, lrate=0.500, error=0.011\n",">epoch=585, lrate=0.500, error=0.011\n",">epoch=590, lrate=0.500, error=0.012\n",">epoch=595, lrate=0.500, error=0.012\n",">epoch=600, lrate=0.500, error=0.011\n",">epoch=605, lrate=0.500, error=0.011\n",">epoch=610, lrate=0.500, error=0.012\n",">epoch=615, lrate=0.500, error=0.012\n",">epoch=620, lrate=0.500, error=0.012\n",">epoch=625, lrate=0.500, error=0.011\n",">epoch=630, lrate=0.500, error=0.011\n",">epoch=635, lrate=0.500, error=0.012\n",">epoch=640, lrate=0.500, error=0.012\n",">epoch=645, lrate=0.500, error=0.012\n",">epoch=650, lrate=0.500, error=0.011\n",">epoch=655, lrate=0.500, error=0.011\n",">epoch=660, lrate=0.500, error=0.012\n",">epoch=665, lrate=0.500, error=0.012\n",">epoch=670, lrate=0.500, error=0.012\n",">epoch=675, lrate=0.500, error=0.011\n",">epoch=680, lrate=0.500, error=0.012\n",">epoch=685, lrate=0.500, error=0.011\n",">epoch=690, lrate=0.500, error=0.011\n",">epoch=695, lrate=0.500, error=0.012\n",">epoch=700, lrate=0.500, error=0.011\n",">epoch=705, lrate=0.500, error=0.011\n",">epoch=710, lrate=0.500, error=0.012\n",">epoch=715, lrate=0.500, error=0.011\n",">epoch=720, lrate=0.500, error=0.011\n",">epoch=725, lrate=0.500, error=0.012\n",">epoch=730, lrate=0.500, error=0.012\n",">epoch=735, lrate=0.500, error=0.012\n",">epoch=740, lrate=0.500, error=0.011\n",">epoch=745, lrate=0.500, error=0.011\n",">epoch=750, lrate=0.500, error=0.011\n",">epoch=755, lrate=0.500, error=0.012\n",">epoch=760, lrate=0.500, error=0.012\n",">epoch=765, lrate=0.500, error=0.009\n",">epoch=770, lrate=0.500, error=0.009\n",">epoch=775, lrate=0.500, error=0.010\n",">epoch=780, lrate=0.500, error=0.009\n",">epoch=785, lrate=0.500, error=0.009\n",">epoch=790, lrate=0.500, error=0.009\n",">epoch=795, lrate=0.500, error=0.010\n",">epoch=800, lrate=0.500, error=0.009\n",">epoch=805, lrate=0.500, error=0.009\n",">epoch=810, lrate=0.500, error=0.009\n",">epoch=815, lrate=0.500, error=0.009\n",">epoch=820, lrate=0.500, error=0.009\n",">epoch=825, lrate=0.500, error=0.010\n",">epoch=830, lrate=0.500, error=0.009\n",">epoch=835, lrate=0.500, error=0.009\n",">epoch=840, lrate=0.500, error=0.009\n",">epoch=845, lrate=0.500, error=0.009\n",">epoch=850, lrate=0.500, error=0.009\n",">epoch=855, lrate=0.500, error=0.006\n",">epoch=860, lrate=0.500, error=0.006\n",">epoch=865, lrate=0.500, error=0.006\n",">epoch=870, lrate=0.500, error=0.007\n",">epoch=875, lrate=0.500, error=0.007\n",">epoch=880, lrate=0.500, error=0.006\n",">epoch=885, lrate=0.500, error=0.006\n",">epoch=890, lrate=0.500, error=0.006\n",">epoch=895, lrate=0.500, error=0.006\n",">epoch=900, lrate=0.500, error=0.006\n",">epoch=905, lrate=0.500, error=0.006\n",">epoch=910, lrate=0.500, error=0.006\n",">epoch=915, lrate=0.500, error=0.006\n",">epoch=920, lrate=0.500, error=0.006\n",">epoch=925, lrate=0.500, error=0.006\n",">epoch=930, lrate=0.500, error=0.006\n",">epoch=935, lrate=0.500, error=0.006\n",">epoch=940, lrate=0.500, error=0.006\n",">epoch=945, lrate=0.500, error=0.006\n",">epoch=950, lrate=0.500, error=0.006\n",">epoch=955, lrate=0.500, error=0.006\n",">epoch=960, lrate=0.500, error=0.006\n",">epoch=965, lrate=0.500, error=0.006\n",">epoch=970, lrate=0.500, error=0.006\n",">epoch=975, lrate=0.500, error=0.006\n",">epoch=980, lrate=0.500, error=0.006\n",">epoch=985, lrate=0.500, error=0.006\n",">epoch=990, lrate=0.500, error=0.006\n",">epoch=995, lrate=0.500, error=0.006\n",">epoch=1000, lrate=0.500, error=0.006\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4y1TKnErhyEG"},"source":["def predict(network, row):\n","\toutputs = forward_propagate(network, row)\n","\treturn outputs[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DqvWlfq5qZ2O"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"_VeUL-TWh7Vb"},"source":["def validasi(dataset):\n","    actual = []\n","    preds = []\n","    for row in dataset:\n","        actual.append(row[-1])\n","        prediction = predict(network, row)\n","        preds.append(int(np.round(prediction)))\n","        print('Expected=%d, Got (actual)=%f, Got (prediction)=%d' % (row[-1], prediction, np.round(prediction)))\n","\n","    result  = pd.DataFrame((actual,preds)).T\n","    result.columns  = (\"actual\", \"preds\")\n","\n","    conf_matrix  =  pd.crosstab(result.actual, result.preds)\n","    conf_matrix\n","\n","    tn  = conf_matrix.iloc[0,0]\n","    fp  = conf_matrix.iloc[0,1]\n","    fn  = conf_matrix.iloc[1,0]\n","    tp  = conf_matrix.iloc[1,1]\n","\n","    accuracy =  (tp+tn)/(tp+tn+fp+fn) * 100\n","    recall =  tp/(tp+fn) * 100\n","    precision  = tp/(tp+fp) * 100\n","    f1Score = 2*(recall*precision)/(recall+precision)\n","\n","    print ('accuracy =  %.3f' % accuracy)\n","    print ('recall =  %.3f'  % recall)\n","    print ('precision =  %.3f' % precision)\n","    print ('f1Score =  %.3f'  % f1Score)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjDA32NSlHTh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ed04cfc-d6ce-4902-81c1-3531a0180ef7"},"source":["validasi(dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.030000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.030000, Got (prediction)=0\n","Expected=0, Got (actual)=0.030000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.970000, Got (prediction)=1\n","accuracy =  100.000\n","recall =  100.000\n","precision =  100.000\n","f1Score =  100.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4KJXwy1nS-T","outputId":"d94dbefd-f2d9-44a7-c769-a2f53c1b32ec"},"source":["validasi(val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.030000, Got (prediction)=0\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","accuracy =  100.000\n","recall =  100.000\n","precision =  100.000\n","f1Score =  100.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huyMKIHappUM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b8cf053-0962-43d8-c09d-cfaf147d99b8"},"source":["validasi(test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=0, Got (actual)=0.020000, Got (prediction)=0\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","Expected=1, Got (actual)=0.990000, Got (prediction)=1\n","Expected=1, Got (actual)=0.980000, Got (prediction)=1\n","accuracy =  100.000\n","recall =  100.000\n","precision =  100.000\n","f1Score =  100.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IwbkC6Gfqj9Z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQzaaIaZq-7v"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"chAceLQ4poJp"},"source":["1. Ubah online learning menjadi batch learning\n","2. Modifikasi train network sehingga bisa menggunakan val data (per 5 epoch)\n","3. Evaluation menggunakan test data (bandingkan dengan accuracy training, validation)"]},{"cell_type":"code","metadata":{"id":"Lj-tY2FUrTbZ"},"source":[""],"execution_count":null,"outputs":[]}]}