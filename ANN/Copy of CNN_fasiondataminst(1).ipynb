{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CNN_fasiondataminst.ipynb","provenance":[{"file_id":"1iMFr8divBWCIVECwXRHB_iumn8cP_SIq","timestamp":1623756489039}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"i48sRYH0W-Xt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623756646636,"user_tz":-420,"elapsed":42863,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"4d74e153-d999-4874-c074-7f257f353c30"},"source":["!pip install --upgrade tensorflow==1.15"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15\n","  Using cached https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl\n","Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n","Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.34.1)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.0.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.5.0)\n","Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n","\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow\n","Successfully installed tensorflow-1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yYHy58XOXPV1","executionInfo":{"status":"ok","timestamp":1623756647973,"user_tz":-420,"elapsed":1341,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}}},"source":["import tensorflow as tf\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"KD4uFXeFXTRq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623756648507,"user_tz":-420,"elapsed":547,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"1928d3b4-77cd-4c98-b103-a6926433df55"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_U0YkxgyX0xl","executionInfo":{"status":"ok","timestamp":1623756648508,"user_tz":-420,"elapsed":7,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}}},"source":["y_train = tf.keras.utils.to_categorical(y_train, num_classes=None)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes=None)\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1ayamNhXUVE","colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"status":"error","timestamp":1623756650474,"user_tz":-420,"elapsed":1970,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"069c676a-cf34-4c46-c01b-d97620411343"},"source":["# We use the Sequential model in keras which is used 99% of the time \n","model = tf.keras.Sequential() \n","# We add our first convolutional layer with 32 neurons and filter size of 3 x 3\n","model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n","# We add our max pooling layer \n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n","# We flatten the features \n","model.add(tf.keras.layers.Flatten()) \n","#We add a second convolutional layer \n","model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu')) \n","# Our dropout layer \n","model.add(tf.keras.layers.Dropout(0.25)) \n","# A fully connected layer \n","model.add(tf.keras.layers.Dense(128, activation='relu')) \n","# Another dropout layer with more dropouts \n","model.add(tf.keras.layers.Dropout(0.5)) \n","# We add an output layer that uses softmax activation for the 10 classes \n","model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, batch_size=128, epochs=12, verbose=1, validation_data=(x_test, y_test))\n","\n","score = model.evaluate(x_test, y_test, verbose=0) \n","print('Test loss:', score[0]) \n","print('Test accuracy:', score[1])\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3a68ee92bccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#We add a second convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Our dropout layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         raise TypeError('All layers in a Sequential model '\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 819\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 5408]"]}]},{"cell_type":"code","metadata":{"id":"D7KCwjcydvQe","executionInfo":{"status":"aborted","timestamp":1623756650472,"user_tz":-420,"elapsed":9,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}}},"source":["# baseline cnn model for fashion mnist\n","from numpy import mean\n","from numpy import std\n","from matplotlib import pyplot\n","from sklearn.model_selection import KFold\n","from keras.datasets import fashion_mnist\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","\n","# load train and test dataset\n","def load_dataset():\n","\t# load dataset\n","\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n","\t# reshape dataset to have a single channel\n","\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n","\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n","\t# one hot encode target values\n","\ttrainY = to_categorical(trainY)\n","\ttestY = to_categorical(testY)\n","\treturn trainX, trainY, testX, testY\n","\n","# scale pixels\n","def prep_pixels(train, test):\n","\t# convert from integers to floats\n","\ttrain_norm = train.astype('float32')\n","\ttest_norm = test.astype('float32')\n","\t# normalize to range 0-1\n","\ttrain_norm = train_norm / 255.0\n","\ttest_norm = test_norm / 255.0\n","\t# return normalized images\n","\treturn train_norm, test_norm\n","\n","# define cnn model\n","def define_model():\n","\tmodel = Sequential()\n","\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n","\tmodel.add(MaxPooling2D((2, 2)))\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n","\tmodel.add(Dense(10, activation='softmax'))\n","\t# compile model\n","\topt = SGD(lr=0.01, momentum=0.9)\n","\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\treturn model\n","\n","# evaluate a model using k-fold cross-validation\n","def evaluate_model(dataX, dataY, n_folds=5):\n","\tscores, histories = list(), list()\n","\t# prepare cross validation\n","\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n","\t# enumerate splits\n","\tfor train_ix, test_ix in kfold.split(dataX):\n","\t\t# define model\n","\t\tmodel = define_model()\n","\t\t# select rows for train and test\n","\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n","\t\t# fit model\n","\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n","\t\t# evaluate model\n","\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n","\t\tprint('> %.3f' % (acc * 100.0))\n","\t\t# append scores\n","\t\tscores.append(acc)\n","\t\thistories.append(history)\n","\treturn scores, histories\n","\n","# plot diagnostic learning curves\n","def summarize_diagnostics(histories):\n","\tfor i in range(len(histories)):\n","\t\t# plot loss\n","\t\tpyplot.subplot(211)\n","\t\tpyplot.title('Cross Entropy Loss')\n","\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n","\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n","\t\t# plot accuracy\n","\t\tpyplot.subplot(212)\n","\t\tpyplot.title('Classification Accuracy')\n","\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n","\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n","\tpyplot.show()\n","\n","# summarize model performance\n","def summarize_performance(scores):\n","\t# print summary\n","\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n","\t# box and whisker plots of results\n","\tpyplot.boxplot(scores)\n","\tpyplot.show()\n","\n","# run the test harness for evaluating a model\n","def run_test_harness():\n","\t# load dataset\n","\ttrainX, trainY, testX, testY = load_dataset()\n","\t# prepare pixel data\n","\ttrainX, testX = prep_pixels(trainX, testX)\n","\t# evaluate model\n","\tscores, histories = evaluate_model(trainX, trainY)\n","\t# learning curves\n","\tsummarize_diagnostics(histories)\n","\t# summarize estimated performance\n","\tsummarize_performance(scores)\n","\n","# entry point, run the test harness\n","run_test_harness()"],"execution_count":null,"outputs":[]}]}