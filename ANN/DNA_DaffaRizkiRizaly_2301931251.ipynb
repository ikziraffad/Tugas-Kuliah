{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DNA_DaffaRizkiRizaly_2301931251.ipynb","provenance":[],"authorship_tag":"ABX9TyPV935JrXIH6G5h3xlp2ykH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rMHQ2iyNbB00"},"source":["#UAS Daffa Rizki Rizaly - 2301931251\n","DNA Dataset"]},{"cell_type":"markdown","metadata":{"id":"1voH5WNJbMOJ"},"source":["#Import Library"]},{"cell_type":"code","metadata":{"id":"JTBe1x9_ammM"},"source":["import tensorflow as tf \n","from tensorflow import keras \n","from keras.models import Sequential \n","from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout\n","from keras.optimizers import Adam\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ohHENReVPSVn"},"source":["* **tensorflow** sebagai library machine learning yang digunakan untuk mengakses keras.\n","* **keras** merupakan API untuk deep learning.\n","* **Sequential** adalah tipe model yang digunakan karena hanya memiliki 1 input tensor dan 1 output tensor.\n","* **Conv1D** digunakan untuk membuat layer convulutional 1D. Pada dataset ini , saya menggunakan 1D karena dataset merupakan data 1D\n","* **MaxPooling1D** digunakan untuk mengurangi dimensi feature map tanpa menghilang bagian paling penting.\n","* **Dense** menambahkan layer yang terkonek dengan erat\n","* **Flatten** digunakan untuk mengubah 2dimensional menjadi 1 linear vector.\n","* **Dropout** digunakan untuk mengdrop sebuah random neuron,'\n","* **Adam** adalah optimizer yang saya gunakan karena memiliki performa yang terbaik.\n","\n","* **train_test_split** digunakan untuk splitting data ke validation set\n","* **PCA** digunakan sebagai library untuk melakukan pca dan pengurangan dimensi gambar\n","* **StandardScaler** digunakan untuk normalisasi data features untuk memperbagus hasil.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eU4DKh8_bRgQ"},"source":["#Import Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"OP4CS1nGbQvt","executionInfo":{"status":"ok","timestamp":1626861960577,"user_tz":-420,"elapsed":620,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"1a2331f7-e5c0-40f5-e145-95173070b98b"},"source":["#Pada bagian ini kita akan membaca dataset dengan pandas dan saya masukan ke data\n","data = pd.read_csv('rawdata.csv')\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SAMPLE_ID</th>\n","      <th>snp_0</th>\n","      <th>snp_1</th>\n","      <th>snp_2</th>\n","      <th>snp_3</th>\n","      <th>snp_4</th>\n","      <th>snp_5</th>\n","      <th>snp_6</th>\n","      <th>snp_7</th>\n","      <th>snp_8</th>\n","      <th>snp_9</th>\n","      <th>snp_10</th>\n","      <th>snp_11</th>\n","      <th>snp_12</th>\n","      <th>snp_13</th>\n","      <th>snp_14</th>\n","      <th>snp_15</th>\n","      <th>snp_16</th>\n","      <th>snp_17</th>\n","      <th>snp_18</th>\n","      <th>snp_19</th>\n","      <th>snp_20</th>\n","      <th>snp_21</th>\n","      <th>snp_22</th>\n","      <th>snp_23</th>\n","      <th>snp_24</th>\n","      <th>snp_25</th>\n","      <th>snp_26</th>\n","      <th>snp_27</th>\n","      <th>snp_28</th>\n","      <th>snp_29</th>\n","      <th>snp_30</th>\n","      <th>snp_31</th>\n","      <th>snp_32</th>\n","      <th>snp_33</th>\n","      <th>snp_34</th>\n","      <th>snp_35</th>\n","      <th>snp_36</th>\n","      <th>snp_37</th>\n","      <th>snp_38</th>\n","      <th>...</th>\n","      <th>snp_9962</th>\n","      <th>snp_9963</th>\n","      <th>snp_9964</th>\n","      <th>snp_9965</th>\n","      <th>snp_9966</th>\n","      <th>snp_9967</th>\n","      <th>snp_9968</th>\n","      <th>snp_9969</th>\n","      <th>snp_9970</th>\n","      <th>snp_9971</th>\n","      <th>snp_9972</th>\n","      <th>snp_9973</th>\n","      <th>snp_9974</th>\n","      <th>snp_9975</th>\n","      <th>snp_9976</th>\n","      <th>snp_9977</th>\n","      <th>snp_9978</th>\n","      <th>snp_9979</th>\n","      <th>snp_9980</th>\n","      <th>snp_9981</th>\n","      <th>snp_9982</th>\n","      <th>snp_9983</th>\n","      <th>snp_9984</th>\n","      <th>snp_9985</th>\n","      <th>snp_9986</th>\n","      <th>snp_9987</th>\n","      <th>snp_9988</th>\n","      <th>snp_9989</th>\n","      <th>snp_9990</th>\n","      <th>snp_9991</th>\n","      <th>snp_9992</th>\n","      <th>snp_9993</th>\n","      <th>snp_9994</th>\n","      <th>snp_9995</th>\n","      <th>snp_9996</th>\n","      <th>snp_9997</th>\n","      <th>snp_9998</th>\n","      <th>snp_9999</th>\n","      <th>snp_10000</th>\n","      <th>STATUS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>HCB181</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>HCB182</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>HCB183</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>HCB184</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HCB185</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>JPT265</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>JPT266</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>JPT267</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>JPT268</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>JPT269</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>89 rows × 10003 columns</p>\n","</div>"],"text/plain":["   SAMPLE_ID  snp_0  snp_1  snp_2  ...  snp_9998  snp_9999  snp_10000  STATUS\n","0     HCB181      1      0      0  ...         2         1          2       1\n","1     HCB182      1      0      0  ...         2         2          2       2\n","2     HCB183      1      0      0  ...         2         1          2       2\n","3     HCB184      1      0      0  ...         2         1          2       2\n","4     HCB185      1      0      0  ...         2         2          2       1\n","..       ...    ...    ...    ...  ...       ...       ...        ...     ...\n","84    JPT265      1      0      0  ...         2         1          1       2\n","85    JPT266      1      0      0  ...         2         1          2       2\n","86    JPT267      1      0      0  ...         1         2          2       1\n","87    JPT268      1      0      0  ...         2         1          1       1\n","88    JPT269      1      0      0  ...         2         2          2       2\n","\n","[89 rows x 10003 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"VtrdX0mubeHe","executionInfo":{"status":"ok","timestamp":1626861961667,"user_tz":-420,"elapsed":1128,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"e828bbf6-987a-4f7c-9857-7096ee52dbed"},"source":["# Saya mengdrop colomn sample_ID karena tidak dibutuhkan.\n","data = data.drop(['SAMPLE_ID'], axis=1)\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>snp_0</th>\n","      <th>snp_1</th>\n","      <th>snp_2</th>\n","      <th>snp_3</th>\n","      <th>snp_4</th>\n","      <th>snp_5</th>\n","      <th>snp_6</th>\n","      <th>snp_7</th>\n","      <th>snp_8</th>\n","      <th>snp_9</th>\n","      <th>snp_10</th>\n","      <th>snp_11</th>\n","      <th>snp_12</th>\n","      <th>snp_13</th>\n","      <th>snp_14</th>\n","      <th>snp_15</th>\n","      <th>snp_16</th>\n","      <th>snp_17</th>\n","      <th>snp_18</th>\n","      <th>snp_19</th>\n","      <th>snp_20</th>\n","      <th>snp_21</th>\n","      <th>snp_22</th>\n","      <th>snp_23</th>\n","      <th>snp_24</th>\n","      <th>snp_25</th>\n","      <th>snp_26</th>\n","      <th>snp_27</th>\n","      <th>snp_28</th>\n","      <th>snp_29</th>\n","      <th>snp_30</th>\n","      <th>snp_31</th>\n","      <th>snp_32</th>\n","      <th>snp_33</th>\n","      <th>snp_34</th>\n","      <th>snp_35</th>\n","      <th>snp_36</th>\n","      <th>snp_37</th>\n","      <th>snp_38</th>\n","      <th>snp_39</th>\n","      <th>...</th>\n","      <th>snp_9962</th>\n","      <th>snp_9963</th>\n","      <th>snp_9964</th>\n","      <th>snp_9965</th>\n","      <th>snp_9966</th>\n","      <th>snp_9967</th>\n","      <th>snp_9968</th>\n","      <th>snp_9969</th>\n","      <th>snp_9970</th>\n","      <th>snp_9971</th>\n","      <th>snp_9972</th>\n","      <th>snp_9973</th>\n","      <th>snp_9974</th>\n","      <th>snp_9975</th>\n","      <th>snp_9976</th>\n","      <th>snp_9977</th>\n","      <th>snp_9978</th>\n","      <th>snp_9979</th>\n","      <th>snp_9980</th>\n","      <th>snp_9981</th>\n","      <th>snp_9982</th>\n","      <th>snp_9983</th>\n","      <th>snp_9984</th>\n","      <th>snp_9985</th>\n","      <th>snp_9986</th>\n","      <th>snp_9987</th>\n","      <th>snp_9988</th>\n","      <th>snp_9989</th>\n","      <th>snp_9990</th>\n","      <th>snp_9991</th>\n","      <th>snp_9992</th>\n","      <th>snp_9993</th>\n","      <th>snp_9994</th>\n","      <th>snp_9995</th>\n","      <th>snp_9996</th>\n","      <th>snp_9997</th>\n","      <th>snp_9998</th>\n","      <th>snp_9999</th>\n","      <th>snp_10000</th>\n","      <th>STATUS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>89 rows × 10002 columns</p>\n","</div>"],"text/plain":["    snp_0  snp_1  snp_2  snp_3  ...  snp_9998  snp_9999  snp_10000  STATUS\n","0       1      0      0      1  ...         2         1          2       1\n","1       1      0      0      1  ...         2         2          2       2\n","2       1      0      0      1  ...         2         1          2       2\n","3       1      0      0      1  ...         2         1          2       2\n","4       1      0      0      1  ...         2         2          2       1\n","..    ...    ...    ...    ...  ...       ...       ...        ...     ...\n","84      1      0      0      1  ...         2         1          1       2\n","85      1      0      0      1  ...         2         1          2       2\n","86      1      0      0      1  ...         1         2          2       1\n","87      1      0      0      1  ...         2         1          1       1\n","88      1      0      0      1  ...         2         2          2       2\n","\n","[89 rows x 10002 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"iQkaFL4yk3fl"},"source":["#Disini kita akan membagi features dan label\n","Features = data.iloc[:, :-1].values\n","Labels = data.iloc[:, -1].values.reshape(-1,1)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oTH77wNcDiR"},"source":["#Kita akan melakukan Normalisasi dataset\n","scaler = StandardScaler()\n","dataset= scaler.fit_transform(Features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JwUYin5gWV2n"},"source":["# Split Dataset for test\n","X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size = 0.3, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbNOrhfoWWZi"},"source":["# Split Dataset for Validation\n","X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-5_2EBLSAjS","executionInfo":{"status":"ok","timestamp":1626861961671,"user_tz":-420,"elapsed":15,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"f63e4d3d-99f3-41cc-ba67-95ee8ee68e1d"},"source":["#Reshape features \n","#Kita akan reshape features sedimikian rupa untuk dapat dimasukan kedalam CNN.\n","input_shape = (X_train.shape[1], 1)\n","\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],  1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n","\n","print('x_train shape: {}'.format(X_train.shape))\n","print('x_test shape: {}'.format(X_test.shape))\n","print('x_validate shape: {}'.format(X_validate.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (49, 10001, 1)\n","x_test shape: (27, 10001, 1)\n","x_validate shape: (13, 10001, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L2OZqHuWcUj4"},"source":["Pada bagian ini kita akan mengkonfigurasi 2 cnn model kita. "]},{"cell_type":"code","metadata":{"id":"F_5QjwJ9BBV0"},"source":["# One-hot encoding\n","#Kita akan encoding agar hasilnya optimal\n","Encoder = OneHotEncoder()\n","y_train = Encoder.fit_transform(y_train).toarray()\n","y_test = Encoder.transform(y_test).toarray()\n","y_validate = Encoder.transform(y_validate).toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qb3EkhT0mn4O"},"source":["#Pada bagian ini, saya membuat 2 model layer.\n","name = '1_Layer'\n","cnn_model_1 = Sequential([\n","    #Menambahkan layer convulational 1D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.                      \n","    Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","\n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling1D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 32 yang terhubung ketat.\n","    Dense(32, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 2 yaitu jumlah label yang terhubung ketat.\n","    Dense(2, activation='softmax', name='Output')\n","], name=name)\n","\n","name = '2_Layer'\n","cnn_model_2 = Sequential([\n","    #Menambahkan layer convulational 1D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","    \n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling1D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout-1'),\n","\n","    #Menambahkan layer convulational 1D dengan 64 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv1D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.25, name='Dropout-2'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 64 yang terhubung ketat.\n","    Dense(64, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 2 yaitu jumlah label yang terhubung ketat.\n","    Dense(2, activation='softmax', name='Output')\n","], name=name)\n","\n","cnn_PCA_models = [cnn_model_1, cnn_model_2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRqQ-UrNmpT-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626861962310,"user_tz":-420,"elapsed":649,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"03c4da88-3616-4a2a-9dc6-feecb577d73d"},"source":["#Melihat summary\n","\n","for model in cnn_models:\n","    model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"1_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv1D)            (None, 9999, 32)          128       \n","_________________________________________________________________\n","MaxPool (MaxPooling1D)       (None, 4999, 32)          0         \n","_________________________________________________________________\n","Dropout (Dropout)            (None, 4999, 32)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 159968)            0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 32)                5119008   \n","_________________________________________________________________\n","Output (Dense)               (None, 2)                 66        \n","=================================================================\n","Total params: 5,119,202\n","Trainable params: 5,119,202\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"2_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv1D)            (None, 9999, 32)          128       \n","_________________________________________________________________\n","MaxPool (MaxPooling1D)       (None, 4999, 32)          0         \n","_________________________________________________________________\n","Dropout-1 (Dropout)          (None, 4999, 32)          0         \n","_________________________________________________________________\n","Conv2D-2 (Conv1D)            (None, 4997, 64)          6208      \n","_________________________________________________________________\n","Dropout-2 (Dropout)          (None, 4997, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 319808)            0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 64)                20467776  \n","_________________________________________________________________\n","Output (Dense)               (None, 2)                 130       \n","=================================================================\n","Total params: 20,474,242\n","Trainable params: 20,474,242\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5nGYTxzYmrkv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626862084482,"user_tz":-420,"elapsed":122174,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"188b26f2-7b39-4f48-f355-5e6458d471fc"},"source":["#Training Model dan menyimpan di history\n","\n","history_dict = {}\n","\n","for model in cnn_models:\n","    model.compile(\n","        loss='binary_crossentropy',\n","        optimizer=Adam(),\n","        metrics=['accuracy']\n","    )\n","    \n","    history = model.fit(\n","        X_train, y_train,\n","        batch_size=20,\n","        epochs=50, verbose=1,\n","        validation_data=(X_validate, y_validate)\n","    )\n","    \n","    history_dict[model.name] = history"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","3/3 [==============================] - 17s 472ms/step - loss: 1.2270 - accuracy: 0.6203 - val_loss: 0.7394 - val_accuracy: 0.4615\n","Epoch 2/50\n","3/3 [==============================] - 0s 141ms/step - loss: 1.3902 - accuracy: 0.4432 - val_loss: 1.9686 - val_accuracy: 0.4615\n","Epoch 3/50\n","3/3 [==============================] - 0s 151ms/step - loss: 1.3128 - accuracy: 0.5153 - val_loss: 1.1744 - val_accuracy: 0.5385\n","Epoch 4/50\n","3/3 [==============================] - 0s 144ms/step - loss: 1.0572 - accuracy: 0.4903 - val_loss: 1.7335 - val_accuracy: 0.4615\n","Epoch 5/50\n","3/3 [==============================] - 0s 147ms/step - loss: 1.0757 - accuracy: 0.5732 - val_loss: 1.5234 - val_accuracy: 0.5385\n","Epoch 6/50\n","3/3 [==============================] - 0s 142ms/step - loss: 1.3467 - accuracy: 0.5489 - val_loss: 1.3174 - val_accuracy: 0.4615\n","Epoch 7/50\n","3/3 [==============================] - 0s 145ms/step - loss: 1.0897 - accuracy: 0.5114 - val_loss: 0.7529 - val_accuracy: 0.4615\n","Epoch 8/50\n","3/3 [==============================] - 0s 140ms/step - loss: 0.6558 - accuracy: 0.7844 - val_loss: 0.9519 - val_accuracy: 0.5385\n","Epoch 9/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.6238 - accuracy: 0.5278 - val_loss: 1.1421 - val_accuracy: 0.4615\n","Epoch 10/50\n","3/3 [==============================] - 0s 141ms/step - loss: 0.4901 - accuracy: 0.7276 - val_loss: 1.2067 - val_accuracy: 0.5385\n","Epoch 11/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.6888 - accuracy: 0.5795 - val_loss: 0.8406 - val_accuracy: 0.3077\n","Epoch 12/50\n","3/3 [==============================] - 0s 149ms/step - loss: 0.4508 - accuracy: 0.7759 - val_loss: 0.9369 - val_accuracy: 0.4615\n","Epoch 13/50\n","3/3 [==============================] - 0s 142ms/step - loss: 0.3405 - accuracy: 0.8552 - val_loss: 1.0736 - val_accuracy: 0.5385\n","Epoch 14/50\n","3/3 [==============================] - 0s 150ms/step - loss: 0.3596 - accuracy: 0.7605 - val_loss: 0.8703 - val_accuracy: 0.3077\n","Epoch 15/50\n","3/3 [==============================] - 0s 141ms/step - loss: 0.2854 - accuracy: 0.9240 - val_loss: 0.8558 - val_accuracy: 0.3077\n","Epoch 16/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.2062 - accuracy: 1.0000 - val_loss: 0.9670 - val_accuracy: 0.5385\n","Epoch 17/50\n","3/3 [==============================] - 0s 144ms/step - loss: 0.2842 - accuracy: 0.9835 - val_loss: 0.9071 - val_accuracy: 0.5385\n","Epoch 18/50\n","3/3 [==============================] - 0s 144ms/step - loss: 0.1531 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.3077\n","Epoch 19/50\n","3/3 [==============================] - 0s 145ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.3077\n","Epoch 20/50\n","3/3 [==============================] - 0s 142ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.9101 - val_accuracy: 0.5385\n","Epoch 21/50\n","3/3 [==============================] - 0s 143ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.8518 - val_accuracy: 0.4615\n","Epoch 22/50\n","3/3 [==============================] - 0s 142ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.3077\n","Epoch 23/50\n","3/3 [==============================] - 0s 149ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.8645 - val_accuracy: 0.3846\n","Epoch 24/50\n","3/3 [==============================] - 0s 146ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.9794 - val_accuracy: 0.5385\n","Epoch 25/50\n","3/3 [==============================] - 0s 144ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.4615\n","Epoch 26/50\n","3/3 [==============================] - 0s 143ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.3077\n","Epoch 27/50\n","3/3 [==============================] - 0s 143ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.3077\n","Epoch 28/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.5385\n","Epoch 29/50\n","3/3 [==============================] - 0s 145ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.4615\n","Epoch 30/50\n","3/3 [==============================] - 0s 154ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.9410 - val_accuracy: 0.4615\n","Epoch 31/50\n","3/3 [==============================] - 0s 146ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.9078 - val_accuracy: 0.5385\n","Epoch 32/50\n","3/3 [==============================] - 0s 150ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.3846\n","Epoch 33/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9152 - val_accuracy: 0.3846\n","Epoch 34/50\n","3/3 [==============================] - 0s 150ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.9188 - val_accuracy: 0.5385\n","Epoch 35/50\n","3/3 [==============================] - 0s 143ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.5385\n","Epoch 36/50\n","3/3 [==============================] - 0s 148ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.3077\n","Epoch 37/50\n","3/3 [==============================] - 0s 143ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.4615\n","Epoch 38/50\n","3/3 [==============================] - 0s 146ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.5385\n","Epoch 39/50\n","3/3 [==============================] - 0s 145ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.3846\n","Epoch 40/50\n","3/3 [==============================] - 0s 142ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.3846\n","Epoch 41/50\n","3/3 [==============================] - 0s 151ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.5385\n","Epoch 42/50\n","3/3 [==============================] - 0s 141ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.5385\n","Epoch 43/50\n","3/3 [==============================] - 0s 154ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9625 - val_accuracy: 0.4615\n","Epoch 44/50\n","3/3 [==============================] - 0s 143ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.5385\n","Epoch 45/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.5385\n","Epoch 46/50\n","3/3 [==============================] - 0s 140ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.5385\n","Epoch 47/50\n","3/3 [==============================] - 0s 149ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.5385\n","Epoch 48/50\n","3/3 [==============================] - 0s 140ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.5385\n","Epoch 49/50\n","3/3 [==============================] - 0s 145ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.5385\n","Epoch 50/50\n","3/3 [==============================] - 0s 147ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.5385\n","Epoch 1/50\n","3/3 [==============================] - 3s 552ms/step - loss: 4.0976 - accuracy: 0.5386 - val_loss: 6.1427 - val_accuracy: 0.5385\n","Epoch 2/50\n","3/3 [==============================] - 1s 384ms/step - loss: 6.7392 - accuracy: 0.4699 - val_loss: 2.7998 - val_accuracy: 0.4615\n","Epoch 3/50\n","3/3 [==============================] - 1s 378ms/step - loss: 3.1174 - accuracy: 0.5364 - val_loss: 2.3760 - val_accuracy: 0.4615\n","Epoch 4/50\n","3/3 [==============================] - 1s 380ms/step - loss: 2.3452 - accuracy: 0.4614 - val_loss: 0.8880 - val_accuracy: 0.5385\n","Epoch 5/50\n","3/3 [==============================] - 1s 376ms/step - loss: 0.9986 - accuracy: 0.4699 - val_loss: 0.9355 - val_accuracy: 0.5385\n","Epoch 6/50\n","3/3 [==============================] - 1s 374ms/step - loss: 1.0052 - accuracy: 0.4268 - val_loss: 0.7750 - val_accuracy: 0.4615\n","Epoch 7/50\n","3/3 [==============================] - 1s 375ms/step - loss: 0.7476 - accuracy: 0.4614 - val_loss: 0.7758 - val_accuracy: 0.4615\n","Epoch 8/50\n","3/3 [==============================] - 1s 374ms/step - loss: 0.7315 - accuracy: 0.4926 - val_loss: 0.7370 - val_accuracy: 0.4615\n","Epoch 9/50\n","3/3 [==============================] - 1s 385ms/step - loss: 0.6299 - accuracy: 0.5989 - val_loss: 0.7061 - val_accuracy: 0.3077\n","Epoch 10/50\n","3/3 [==============================] - 1s 381ms/step - loss: 0.6358 - accuracy: 0.6430 - val_loss: 0.7130 - val_accuracy: 0.5385\n","Epoch 11/50\n","3/3 [==============================] - 1s 377ms/step - loss: 0.6613 - accuracy: 0.5301 - val_loss: 0.7293 - val_accuracy: 0.5385\n","Epoch 12/50\n","3/3 [==============================] - 1s 377ms/step - loss: 0.6747 - accuracy: 0.5114 - val_loss: 0.7260 - val_accuracy: 0.5385\n","Epoch 13/50\n","3/3 [==============================] - 1s 382ms/step - loss: 0.6196 - accuracy: 0.5709 - val_loss: 0.7300 - val_accuracy: 0.5385\n","Epoch 14/50\n","3/3 [==============================] - 1s 377ms/step - loss: 0.6020 - accuracy: 0.9240 - val_loss: 0.7425 - val_accuracy: 0.3077\n","Epoch 15/50\n","3/3 [==============================] - 1s 388ms/step - loss: 0.5829 - accuracy: 0.7048 - val_loss: 0.7618 - val_accuracy: 0.3846\n","Epoch 16/50\n","3/3 [==============================] - 1s 381ms/step - loss: 0.5462 - accuracy: 0.9710 - val_loss: 0.7985 - val_accuracy: 0.3846\n","Epoch 17/50\n","3/3 [==============================] - 1s 384ms/step - loss: 0.5118 - accuracy: 0.9710 - val_loss: 0.8503 - val_accuracy: 0.4615\n","Epoch 18/50\n","3/3 [==============================] - 1s 381ms/step - loss: 0.4709 - accuracy: 0.9710 - val_loss: 0.8849 - val_accuracy: 0.3077\n","Epoch 19/50\n","3/3 [==============================] - 1s 375ms/step - loss: 0.4349 - accuracy: 0.8088 - val_loss: 0.9247 - val_accuracy: 0.3077\n","Epoch 20/50\n","3/3 [==============================] - 1s 380ms/step - loss: 0.3393 - accuracy: 0.9898 - val_loss: 0.9680 - val_accuracy: 0.5385\n","Epoch 21/50\n","3/3 [==============================] - 1s 379ms/step - loss: 0.3205 - accuracy: 0.9256 - val_loss: 0.9700 - val_accuracy: 0.3077\n","Epoch 22/50\n","3/3 [==============================] - 1s 384ms/step - loss: 0.2554 - accuracy: 0.9546 - val_loss: 1.0039 - val_accuracy: 0.6154\n","Epoch 23/50\n","3/3 [==============================] - 1s 375ms/step - loss: 0.1974 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.4615\n","Epoch 24/50\n","3/3 [==============================] - 1s 366ms/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.6154\n","Epoch 25/50\n","3/3 [==============================] - 1s 368ms/step - loss: 0.1383 - accuracy: 1.0000 - val_loss: 1.0635 - val_accuracy: 0.3077\n","Epoch 26/50\n","3/3 [==============================] - 1s 372ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 1.1063 - val_accuracy: 0.3077\n","Epoch 27/50\n","3/3 [==============================] - 1s 387ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.5385\n","Epoch 28/50\n","3/3 [==============================] - 1s 386ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.3077\n","Epoch 29/50\n","3/3 [==============================] - 1s 387ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2159 - val_accuracy: 0.3077\n","Epoch 30/50\n","3/3 [==============================] - 1s 375ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.5385\n","Epoch 31/50\n","3/3 [==============================] - 1s 385ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.4615\n","Epoch 32/50\n","3/3 [==============================] - 1s 382ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3856 - val_accuracy: 0.3077\n","Epoch 33/50\n","3/3 [==============================] - 1s 381ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.4615\n","Epoch 34/50\n","3/3 [==============================] - 1s 381ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4791 - val_accuracy: 0.4615\n","Epoch 35/50\n","3/3 [==============================] - 1s 382ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.5385\n","Epoch 36/50\n","3/3 [==============================] - 1s 376ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.3846\n","Epoch 37/50\n","3/3 [==============================] - 1s 381ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5030 - val_accuracy: 0.3077\n","Epoch 38/50\n","3/3 [==============================] - 1s 380ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4305 - val_accuracy: 0.3077\n","Epoch 39/50\n","3/3 [==============================] - 1s 380ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4801 - val_accuracy: 0.4615\n","Epoch 40/50\n","3/3 [==============================] - 1s 382ms/step - loss: 9.2151e-04 - accuracy: 1.0000 - val_loss: 1.5774 - val_accuracy: 0.5385\n","Epoch 41/50\n","3/3 [==============================] - 1s 379ms/step - loss: 9.3352e-04 - accuracy: 1.0000 - val_loss: 1.5640 - val_accuracy: 0.4615\n","Epoch 42/50\n","3/3 [==============================] - 1s 376ms/step - loss: 8.7985e-04 - accuracy: 1.0000 - val_loss: 1.4903 - val_accuracy: 0.4615\n","Epoch 43/50\n","3/3 [==============================] - 1s 377ms/step - loss: 7.2724e-04 - accuracy: 1.0000 - val_loss: 1.4747 - val_accuracy: 0.4615\n","Epoch 44/50\n","3/3 [==============================] - 1s 383ms/step - loss: 5.9817e-04 - accuracy: 1.0000 - val_loss: 1.4770 - val_accuracy: 0.3846\n","Epoch 45/50\n","3/3 [==============================] - 1s 382ms/step - loss: 5.8410e-04 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.4615\n","Epoch 46/50\n","3/3 [==============================] - 1s 381ms/step - loss: 4.3700e-04 - accuracy: 1.0000 - val_loss: 1.4914 - val_accuracy: 0.4615\n","Epoch 47/50\n","3/3 [==============================] - 1s 381ms/step - loss: 4.4558e-04 - accuracy: 1.0000 - val_loss: 1.5111 - val_accuracy: 0.4615\n","Epoch 48/50\n","3/3 [==============================] - 1s 383ms/step - loss: 4.5855e-04 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.4615\n","Epoch 49/50\n","3/3 [==============================] - 1s 376ms/step - loss: 4.6812e-04 - accuracy: 1.0000 - val_loss: 1.5554 - val_accuracy: 0.4615\n","Epoch 50/50\n","3/3 [==============================] - 1s 379ms/step - loss: 4.8287e-04 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 0.4615\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80ec2i_7Bd1W","executionInfo":{"status":"ok","timestamp":1626862084483,"user_tz":-420,"elapsed":18,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"c1e96606-bcd8-4cfc-f7b0-0d610c70be4d"},"source":["#Evaluation\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 1.1609293222427368\n","Test accuracy: 48.148149251937866\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UiqK15nYpdjr"},"source":["Model saya menghasilkan accuracy 48,14% dengan loss 1.16. Hasilnya kurang optimal dan dapat dikembangkan dengan memperbanyak training set,mengatur konfigurasi model,batch learning dan mengatur epoch untuk menghasilkan hasil yang optimal."]},{"cell_type":"markdown","metadata":{"id":"mTqQMVSKBgtp"},"source":["#PCA + CNN"]},{"cell_type":"code","metadata":{"id":"w4KYgKpnBgGm"},"source":["#Masukan ke PCA\n","pca = PCA(n_components=50)\n","pca = pca.fit(Features)\n","Features = pca.transform(Features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlHi5iHmCSi7"},"source":["# Split Dataset for test\n","X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size = 0.3, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcJWzwxYCU9x"},"source":["# Split Dataset for Validation\n","X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Y4tS8zZL5YZ"},"source":["# One-hot encoding\n","Encoder = OneHotEncoder()\n","y_train = Encoder.fit_transform(y_train).toarray()\n","y_test = Encoder.transform(y_test).toarray()\n","y_validate = Encoder.transform(y_validate).toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OImx2hKCYmD","executionInfo":{"status":"ok","timestamp":1626862084485,"user_tz":-420,"elapsed":14,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"ac37f9f1-45cf-4343-9c59-be7833037d31"},"source":["#Reshape features \n","\n","input_shape = (X_train.shape[1], 1)\n","\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],  1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","X_validate = X_validate.reshape(X_validate.shape[0],X_validate.shape[1],1)\n","\n","print('x_train shape: {}'.format(X_train.shape))\n","print('x_test shape: {}'.format(X_test.shape))\n","print('x_validate shape: {}'.format(X_validate.shape))\n","print('y_train shape: {}'.format(y_train.shape))\n","print('y_test shape: {}'.format(y_test.shape))\n","print('y_validate shape: {}'.format(y_validate.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (49, 50, 1)\n","x_test shape: (27, 50, 1)\n","x_validate shape: (13, 50, 1)\n","y_train shape: (49, 2)\n","y_test shape: (27, 2)\n","y_validate shape: (13, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aRJiJBa1lb4s"},"source":["#Build the model"]},{"cell_type":"markdown","metadata":{"id":"sxPi-vnQlTv-"},"source":["Pada bagian ini kita akan mengkonfigurasi 2 cnn model kita. "]},{"cell_type":"code","metadata":{"id":"K8L2GKrzCfoX"},"source":["#Pada bagian ini, saya membuat 2 model layer.\n","name = '1_Layer'\n","cnn_model_1 = Sequential([\n","    #Menambahkan layer convulational 1D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.                      \n","    Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","\n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling1D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 32 yang terhubung ketat.\n","    Dense(32, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 2 yaitu jumlah label yang terhubung ketat.\n","    Dense(2, activation='softmax', name='Output')\n","], name=name)\n","\n","name = '2_Layer'\n","cnn_model_2 = Sequential([\n","    #Menambahkan layer convulational 1D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","    \n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling1D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout-1'),\n","\n","    #Menambahkan layer convulational 1D dengan 64 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv1D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.25, name='Dropout-2'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 64 yang terhubung ketat.\n","    Dense(64, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 2 yaitu jumlah label yang terhubung ketat.\n","    Dense(2, activation='softmax', name='Output')\n","], name=name)\n","\n","cnn_PCA_models = [cnn_model_1, cnn_model_2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2mLpy-ICgtV","executionInfo":{"status":"ok","timestamp":1626862084486,"user_tz":-420,"elapsed":12,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"b82d3ae7-0d83-4670-e088-b21cd2ec2dd9"},"source":["# the model summaries\n","\n","for model in cnn_PCA_models:\n","    model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"1_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv1D)            (None, 48, 32)            128       \n","_________________________________________________________________\n","MaxPool (MaxPooling1D)       (None, 24, 32)            0         \n","_________________________________________________________________\n","Dropout (Dropout)            (None, 24, 32)            0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 768)               0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 32)                24608     \n","_________________________________________________________________\n","Output (Dense)               (None, 2)                 66        \n","=================================================================\n","Total params: 24,802\n","Trainable params: 24,802\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"2_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv1D)            (None, 48, 32)            128       \n","_________________________________________________________________\n","MaxPool (MaxPooling1D)       (None, 24, 32)            0         \n","_________________________________________________________________\n","Dropout-1 (Dropout)          (None, 24, 32)            0         \n","_________________________________________________________________\n","Conv2D-2 (Conv1D)            (None, 22, 64)            6208      \n","_________________________________________________________________\n","Dropout-2 (Dropout)          (None, 22, 64)            0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1408)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 64)                90176     \n","_________________________________________________________________\n","Output (Dense)               (None, 2)                 130       \n","=================================================================\n","Total params: 96,642\n","Trainable params: 96,642\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYGRpATPChsx","executionInfo":{"status":"ok","timestamp":1626862091773,"user_tz":-420,"elapsed":7298,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"b4452e57-2bfe-41dc-ee36-67d3f2a86db6"},"source":["#Training Model dan menyimpan di history\n","\n","history_dict = {}\n","\n","for model in cnn_PCA_models:\n","    model.compile(\n","        loss='binary_crossentropy',\n","        optimizer=Adam(),\n","        metrics=['accuracy']\n","    )\n","    \n","    history = model.fit(\n","        X_train, y_train,\n","        batch_size=20,\n","        epochs=50, verbose=1,\n","        validation_data=(X_validate, y_validate)\n","    )\n","    \n","    history_dict[model.name] = history"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","3/3 [==============================] - 1s 168ms/step - loss: 0.9346 - accuracy: 0.4864 - val_loss: 0.7717 - val_accuracy: 0.3846\n","Epoch 2/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.7669 - accuracy: 0.5278 - val_loss: 0.7812 - val_accuracy: 0.3846\n","Epoch 3/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.5581 - accuracy: 0.8496 - val_loss: 0.7775 - val_accuracy: 0.5385\n","Epoch 4/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.5004 - accuracy: 0.7753 - val_loss: 0.8090 - val_accuracy: 0.6154\n","Epoch 5/50\n","3/3 [==============================] - 0s 21ms/step - loss: 0.4117 - accuracy: 0.8888 - val_loss: 0.8147 - val_accuracy: 0.6154\n","Epoch 6/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3743 - accuracy: 0.9467 - val_loss: 0.7994 - val_accuracy: 0.5385\n","Epoch 7/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3689 - accuracy: 0.9319 - val_loss: 0.8108 - val_accuracy: 0.5385\n","Epoch 8/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 0.9138 - val_loss: 0.8308 - val_accuracy: 0.5385\n","Epoch 9/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3117 - accuracy: 0.9546 - val_loss: 0.8306 - val_accuracy: 0.5385\n","Epoch 10/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.2622 - accuracy: 0.9421 - val_loss: 0.8547 - val_accuracy: 0.5385\n","Epoch 11/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.2277 - accuracy: 0.9898 - val_loss: 0.8779 - val_accuracy: 0.5385\n","Epoch 12/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.2351 - accuracy: 0.9421 - val_loss: 0.9032 - val_accuracy: 0.5385\n","Epoch 13/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.1740 - accuracy: 0.9710 - val_loss: 0.9271 - val_accuracy: 0.5385\n","Epoch 14/50\n","3/3 [==============================] - 0s 12ms/step - loss: 0.1577 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.5385\n","Epoch 15/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.5385\n","Epoch 16/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.1519 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.5385\n","Epoch 17/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.1368 - accuracy: 0.9710 - val_loss: 1.0209 - val_accuracy: 0.5385\n","Epoch 18/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 1.0405 - val_accuracy: 0.5385\n","Epoch 19/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 1.0694 - val_accuracy: 0.5385\n","Epoch 20/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.5385\n","Epoch 21/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.5385\n","Epoch 22/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 1.1723 - val_accuracy: 0.4615\n","Epoch 23/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.4615\n","Epoch 24/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 1.2049 - val_accuracy: 0.4615\n","Epoch 25/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.4615\n","Epoch 26/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.4615\n","Epoch 27/50\n","3/3 [==============================] - 0s 12ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 1.2705 - val_accuracy: 0.3846\n","Epoch 28/50\n","3/3 [==============================] - 0s 12ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.3846\n","Epoch 29/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.3065 - val_accuracy: 0.3846\n","Epoch 30/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.3846\n","Epoch 31/50\n","3/3 [==============================] - 0s 12ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.3846\n","Epoch 32/50\n","3/3 [==============================] - 0s 22ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.3846\n","Epoch 33/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.3846\n","Epoch 34/50\n","3/3 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.3846\n","Epoch 35/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.3850 - val_accuracy: 0.3846\n","Epoch 36/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.3974 - val_accuracy: 0.3846\n","Epoch 37/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.4269 - val_accuracy: 0.3846\n","Epoch 38/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.4797 - val_accuracy: 0.3846\n","Epoch 39/50\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.4908 - val_accuracy: 0.3846\n","Epoch 40/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.4507 - val_accuracy: 0.3846\n","Epoch 41/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.4456 - val_accuracy: 0.3846\n","Epoch 42/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.4555 - val_accuracy: 0.3846\n","Epoch 43/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.3846\n","Epoch 44/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.5224 - val_accuracy: 0.3846\n","Epoch 45/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.5536 - val_accuracy: 0.3846\n","Epoch 46/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5621 - val_accuracy: 0.3846\n","Epoch 47/50\n","3/3 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.3846\n","Epoch 48/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.5463 - val_accuracy: 0.3846\n","Epoch 49/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.5512 - val_accuracy: 0.3846\n","Epoch 50/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.5618 - val_accuracy: 0.3846\n","Epoch 1/50\n","3/3 [==============================] - 1s 193ms/step - loss: 0.7480 - accuracy: 0.4659 - val_loss: 0.7123 - val_accuracy: 0.6154\n","Epoch 2/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.7047 - accuracy: 0.5778 - val_loss: 0.7134 - val_accuracy: 0.5385\n","Epoch 3/50\n","3/3 [==============================] - 0s 14ms/step - loss: 0.6434 - accuracy: 0.6680 - val_loss: 0.7347 - val_accuracy: 0.4615\n","Epoch 4/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.5504 - accuracy: 0.7628 - val_loss: 0.7624 - val_accuracy: 0.4615\n","Epoch 5/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.5303 - accuracy: 0.7571 - val_loss: 0.7700 - val_accuracy: 0.4615\n","Epoch 6/50\n","3/3 [==============================] - 0s 21ms/step - loss: 0.5010 - accuracy: 0.8286 - val_loss: 0.7576 - val_accuracy: 0.5385\n","Epoch 7/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4737 - accuracy: 0.8434 - val_loss: 0.7717 - val_accuracy: 0.3846\n","Epoch 8/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.4651 - accuracy: 0.8700 - val_loss: 0.8129 - val_accuracy: 0.4615\n","Epoch 9/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3598 - accuracy: 0.9342 - val_loss: 0.8406 - val_accuracy: 0.4615\n","Epoch 10/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.2856 - accuracy: 0.9256 - val_loss: 0.8533 - val_accuracy: 0.4615\n","Epoch 11/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.2791 - accuracy: 0.9671 - val_loss: 0.8671 - val_accuracy: 0.5385\n","Epoch 12/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.2691 - accuracy: 0.9546 - val_loss: 0.9098 - val_accuracy: 0.5385\n","Epoch 13/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.2306 - accuracy: 0.9546 - val_loss: 1.0600 - val_accuracy: 0.4615\n","Epoch 14/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.1671 - accuracy: 0.9835 - val_loss: 1.2043 - val_accuracy: 0.4615\n","Epoch 15/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.1573 - accuracy: 0.9444 - val_loss: 1.1008 - val_accuracy: 0.4615\n","Epoch 16/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.1757 - accuracy: 0.9256 - val_loss: 0.9806 - val_accuracy: 0.6154\n","Epoch 17/50\n","3/3 [==============================] - 0s 22ms/step - loss: 0.1290 - accuracy: 0.9546 - val_loss: 1.0060 - val_accuracy: 0.5385\n","Epoch 18/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 0.5385\n","Epoch 19/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0915 - accuracy: 0.9631 - val_loss: 1.0855 - val_accuracy: 0.6154\n","Epoch 20/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 1.1061 - val_accuracy: 0.5385\n","Epoch 21/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.6154\n","Epoch 22/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 1.2774 - val_accuracy: 0.6154\n","Epoch 23/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.2950 - val_accuracy: 0.6154\n","Epoch 24/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0584 - accuracy: 0.9733 - val_loss: 1.1870 - val_accuracy: 0.5385\n","Epoch 25/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.0377 - accuracy: 0.9898 - val_loss: 1.1306 - val_accuracy: 0.6154\n","Epoch 26/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.5385\n","Epoch 27/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 1.4343 - val_accuracy: 0.5385\n","Epoch 28/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.5419 - val_accuracy: 0.4615\n","Epoch 29/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.4348 - val_accuracy: 0.5385\n","Epoch 30/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.2989 - val_accuracy: 0.6154\n","Epoch 31/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 1.2581 - val_accuracy: 0.5385\n","Epoch 32/50\n","3/3 [==============================] - 0s 20ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.2671 - val_accuracy: 0.5385\n","Epoch 33/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.6154\n","Epoch 34/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.4030 - val_accuracy: 0.5385\n","Epoch 35/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.3724 - val_accuracy: 0.6154\n","Epoch 36/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.3486 - val_accuracy: 0.6154\n","Epoch 37/50\n","3/3 [==============================] - 0s 20ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3495 - val_accuracy: 0.5385\n","Epoch 38/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4184 - val_accuracy: 0.6154\n","Epoch 39/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.5081 - val_accuracy: 0.5385\n","Epoch 40/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.5385\n","Epoch 41/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.6094 - val_accuracy: 0.5385\n","Epoch 42/50\n","3/3 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.6511 - val_accuracy: 0.5385\n","Epoch 43/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.6672 - val_accuracy: 0.5385\n","Epoch 44/50\n","3/3 [==============================] - 0s 16ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.6165 - val_accuracy: 0.5385\n","Epoch 45/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.4615\n","Epoch 46/50\n","3/3 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6304 - val_accuracy: 0.4615\n","Epoch 47/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.7764 - val_accuracy: 0.5385\n","Epoch 48/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9120 - val_accuracy: 0.5385\n","Epoch 49/50\n","3/3 [==============================] - 0s 17ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.9730 - val_accuracy: 0.5385\n","Epoch 50/50\n","3/3 [==============================] - 0s 19ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.6856 - val_accuracy: 0.6154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0299RneCj3a","executionInfo":{"status":"ok","timestamp":1626862091774,"user_tz":-420,"elapsed":14,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"7e265d56-27ba-4c82-fc62-d301da6c70dd"},"source":["#Evaluation\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 2.0384085178375244\n","Test accuracy: 44.44444477558136\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G4LdzyZfqrfw"},"source":["Model PCA+CNN saya menghasilkan accuracy 44,44% dengan loss 2. Hasilnya kurang optimal dan dapat dikembangkan dengan memperbanyak training set,mengatur konfigurasi model,mengatur batch learning dan mengatur epoch untuk menghasilkan hasil yang optimal. Untuk PCA+CNN ini , n_components PCA juga pastinya berpengaruh."]},{"cell_type":"markdown","metadata":{"id":"s3X7YFremZiW"},"source":["#Analysis"]},{"cell_type":"markdown","metadata":{"id":"DGlH38Jbj93Z"},"source":["![image.png](data:image/png;base64,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)\n","\n","Terlihat pada tabel diatas, CNN mengungguli dibanding dengan PCA+CNN. PCA+CNN mendapatkan hasil 44%. Sedangkan CNN mendapatkan hasil 48%. Model CNN dapat ditingkatkan dengan mengubah konfigurasi CNNnya dan juga mengatur jumlah Batch Learning dan epoch. Sedangkan Model PCA+CNN juga akan berubah tergantung dengan N_componentsnya. Menurut saya , CNN dapat menghasilkan yang lebih bagus karena  ini terjadi karena PCA sendiri sudah menyederhanakan data dan dapat mengurangi redudansi menjadi data dengan varian yang lebih maksimal, yaitu yang awalnya variable nya berkolerasi, menjadi variable yang bebas atau tidak berkolerasi sehingga hasil kurang bagus. Dengan dataset yang tidak terlalu besar , PCA kurang dapat dipakai dengan optimal."]}]}