{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" Fashion Mnist_Daffa Rizki Rizaly_2301931251.ipynb","provenance":[{"file_id":"1COfyDPbGi6K27MicsufFRfmoS2OTUkiQ","timestamp":1626714116654},{"file_id":"1qvK5jM5vX6nvhmAaQFMlPu0HF-JBBVW7","timestamp":1624462202853}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wxqNoA9ofhTa"},"source":["#UAS Daffa Rizki Rizaly - 2301931251\n","Fashion Mnist Dataset"]},{"cell_type":"markdown","metadata":{"id":"q84BqOLkSrnn"},"source":["## Import Library"]},{"cell_type":"code","metadata":{"id":"cIG0pGxae6w6"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from keras.optimizers import Adam\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y4WneUlXr19m"},"source":["* **tensorflow** sebagai library machine learning yang digunakan untuk mengakses keras.\n","* **keras** merupakan API untuk deep learning.\n","* **Sequential** adalah tipe model yang digunakan karena hanya memiliki 1 input tensor dan 1 output tensor.\n","* **Conv1D** digunakan untuk membuat layer convulutional 1D. Pada dataset ini , saya menggunakan 1D karena dataset merupakan data 1D\n","* **MaxPooling1D** digunakan untuk mengurangi dimensi feature map tanpa menghilang bagian paling penting.\n","* **Dense** menambahkan layer yang terkonek dengan erat\n","* **Flatten** digunakan untuk mengubah 2dimensional menjadi 1 linear vector.\n","* **Dropout** digunakan untuk mengdrop sebuah random neuron,'\n","* **Adam** adalah optimizer yang saya gunakan karena memiliki performa yang terbaik.\n","\n","* **train_test_split** digunakan untuk splitting data ke validation set\n","* **PCA** digunakan sebagai library untuk melakukan pca dan pengurangan dimensi gambar\n","* **StandardScaler** digunakan untuk normalisasi data features untuk memperbagus hasil.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7XJ-RC7PSw4l"},"source":["## Import Dataset"]},{"cell_type":"code","metadata":{"id":"rq_cdYhhguPv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626863921553,"user_tz":-420,"elapsed":883,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"6d719230-39e6-49bd-9b00-dbc23fd37f86"},"source":["fashion_mnist = keras.datasets.fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B_DgEdo6S0Mq"},"source":["## Dataset Preprocessing"]},{"cell_type":"code","metadata":{"id":"-SpLPUd02wIl"},"source":["#Normalize Dataset\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fS-xIfGI3L9w"},"source":["# Split Dataset for Validation\n","X_train, X_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyGSzuJF4Pk2","executionInfo":{"status":"ok","timestamp":1626863922066,"user_tz":-420,"elapsed":5,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"f5b1a2dd-a271-4842-fb22-47e5621a5d7a"},"source":["#Reshape features \n","image_rows = 28\n","image_cols = 28\n","input_shape = (image_rows, image_cols, 1) #Ubah shape menjadi 4d untuk dapat dimasukan ke CNN\n","\n","X_train = X_train.reshape(X_train.shape[0], image_rows, image_cols, 1)\n","X_test = x_test.reshape(x_test.shape[0], image_rows, image_cols, 1)\n","X_validate = X_validate.reshape(X_validate.shape[0], image_rows, image_cols, 1)\n","\n","print('x_train shape: {}'.format(X_train.shape))\n","print('x_test shape: {}'.format(X_test.shape))\n","print('x_validate shape: {}'.format(X_validate.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (48000, 28, 28, 1)\n","x_test shape: (10000, 28, 28, 1)\n","x_validate shape: (12000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nPc4DvzSZAaS"},"source":["## **Build the model**"]},{"cell_type":"markdown","metadata":{"id":"e-Hrj8WUlXNz"},"source":["Pada bagian ini kita akan mengkonfigurasi 2 cnn model kita. "]},{"cell_type":"code","metadata":{"id":"wEf_2aY7FHhX"},"source":["#Pada bagian ini, saya membuat 2 model layer.\n","name = '1_Layer'\n","cnn_model_1 = Sequential([\n","    #Menambahkan layer convulational 2D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.                      \n","    Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","\n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling1D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 32 yang terhubung ketat.\n","    Dense(32, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 10 yaitu jumlah label yang terhubung ketat.\n","    Dense(10, activation='softmax', name='Output')\n","], name=name)\n","\n","name = '2_Layer'\n","cnn_model_2 = Sequential([\n","    #Menambahkan layer convulational 2D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","    \n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling2D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout-1'),\n","\n","    #Menambahkan layer convulational 2D dengan 64 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.25, name='Dropout-2'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 64 yang terhubung ketat.\n","    Dense(64, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 10 yaitu jumlah label yang terhubung ketat.\n","    Dense(10, activation='softmax', name='Output')\n","], name=name)\n","\n","cnn_PCA_models = [cnn_model_1, cnn_model_2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOdTKUvW0zLI","executionInfo":{"status":"ok","timestamp":1626863928008,"user_tz":-420,"elapsed":6,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"adfdcbb2-4617-4e27-8553-638c6a319413"},"source":["#Melihat summary\n","\n","for model in cnn_models:\n","    model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"1_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Dropout (Dropout)            (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 5408)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 32)                173088    \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                330       \n","=================================================================\n","Total params: 173,738\n","Trainable params: 173,738\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"2_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 7744)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 64)                495680    \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                650       \n","=================================================================\n","Total params: 515,146\n","Trainable params: 515,146\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQocqqCw9vAF","executionInfo":{"status":"ok","timestamp":1626864082056,"user_tz":-420,"elapsed":154052,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"8eeb9613-678d-47e5-e2ac-a2d36e8a93e5"},"source":["#Training Model dan menyimpan di history\n","\n","history_dict = {}\n","\n","for model in cnn_models:\n","    model.compile(\n","        loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(),\n","        metrics=['accuracy']\n","    )\n","    \n","    history = model.fit(\n","        X_train, y_train,\n","        batch_size=300,\n","        epochs=50, verbose=1,\n","        validation_data=(X_validate, y_validate)\n","    )\n","    \n","    history_dict[model.name] = history"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","160/160 [==============================] - 44s 9ms/step - loss: 1.0150 - accuracy: 0.6843 - val_loss: 0.4387 - val_accuracy: 0.8465\n","Epoch 2/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4135 - accuracy: 0.8551 - val_loss: 0.3611 - val_accuracy: 0.8737\n","Epoch 3/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3461 - accuracy: 0.8785 - val_loss: 0.3242 - val_accuracy: 0.8847\n","Epoch 4/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3207 - accuracy: 0.8873 - val_loss: 0.3110 - val_accuracy: 0.8919\n","Epoch 5/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2953 - accuracy: 0.8982 - val_loss: 0.3049 - val_accuracy: 0.8913\n","Epoch 6/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2828 - accuracy: 0.8999 - val_loss: 0.2880 - val_accuracy: 0.8977\n","Epoch 7/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2743 - accuracy: 0.9035 - val_loss: 0.2845 - val_accuracy: 0.8954\n","Epoch 8/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2647 - accuracy: 0.9070 - val_loss: 0.2758 - val_accuracy: 0.9028\n","Epoch 9/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2531 - accuracy: 0.9105 - val_loss: 0.2752 - val_accuracy: 0.9016\n","Epoch 10/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2424 - accuracy: 0.9134 - val_loss: 0.2752 - val_accuracy: 0.9016\n","Epoch 11/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2362 - accuracy: 0.9173 - val_loss: 0.2614 - val_accuracy: 0.9048\n","Epoch 12/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9176 - val_loss: 0.2652 - val_accuracy: 0.9058\n","Epoch 13/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2211 - accuracy: 0.9213 - val_loss: 0.2545 - val_accuracy: 0.9091\n","Epoch 14/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2150 - accuracy: 0.9223 - val_loss: 0.2562 - val_accuracy: 0.9069\n","Epoch 15/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2143 - accuracy: 0.9252 - val_loss: 0.2581 - val_accuracy: 0.9095\n","Epoch 16/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2040 - accuracy: 0.9276 - val_loss: 0.2521 - val_accuracy: 0.9116\n","Epoch 17/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2006 - accuracy: 0.9280 - val_loss: 0.2478 - val_accuracy: 0.9118\n","Epoch 18/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1957 - accuracy: 0.9280 - val_loss: 0.2487 - val_accuracy: 0.9109\n","Epoch 19/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1884 - accuracy: 0.9326 - val_loss: 0.2464 - val_accuracy: 0.9120\n","Epoch 20/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1829 - accuracy: 0.9329 - val_loss: 0.2455 - val_accuracy: 0.9098\n","Epoch 21/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9335 - val_loss: 0.2471 - val_accuracy: 0.9140\n","Epoch 22/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1799 - accuracy: 0.9338 - val_loss: 0.2504 - val_accuracy: 0.9111\n","Epoch 23/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1771 - accuracy: 0.9365 - val_loss: 0.2486 - val_accuracy: 0.9124\n","Epoch 24/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1661 - accuracy: 0.9389 - val_loss: 0.2463 - val_accuracy: 0.9137\n","Epoch 25/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1727 - accuracy: 0.9374 - val_loss: 0.2433 - val_accuracy: 0.9154\n","Epoch 26/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1583 - accuracy: 0.9426 - val_loss: 0.2515 - val_accuracy: 0.9133\n","Epoch 27/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1608 - accuracy: 0.9412 - val_loss: 0.2530 - val_accuracy: 0.9115\n","Epoch 28/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1494 - accuracy: 0.9464 - val_loss: 0.2484 - val_accuracy: 0.9116\n","Epoch 29/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.9449 - val_loss: 0.2430 - val_accuracy: 0.9137\n","Epoch 30/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1509 - accuracy: 0.9452 - val_loss: 0.2572 - val_accuracy: 0.9103\n","Epoch 31/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1496 - accuracy: 0.9454 - val_loss: 0.2474 - val_accuracy: 0.9154\n","Epoch 32/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1421 - accuracy: 0.9487 - val_loss: 0.2444 - val_accuracy: 0.9175\n","Epoch 33/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1367 - accuracy: 0.9490 - val_loss: 0.2480 - val_accuracy: 0.9153\n","Epoch 34/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9492 - val_loss: 0.2583 - val_accuracy: 0.9141\n","Epoch 35/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1372 - accuracy: 0.9504 - val_loss: 0.2513 - val_accuracy: 0.9164\n","Epoch 36/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1314 - accuracy: 0.9504 - val_loss: 0.2560 - val_accuracy: 0.9150\n","Epoch 37/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1286 - accuracy: 0.9523 - val_loss: 0.2566 - val_accuracy: 0.9159\n","Epoch 38/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1264 - accuracy: 0.9546 - val_loss: 0.2488 - val_accuracy: 0.9178\n","Epoch 39/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1278 - accuracy: 0.9532 - val_loss: 0.2480 - val_accuracy: 0.9182\n","Epoch 40/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1252 - accuracy: 0.9529 - val_loss: 0.2521 - val_accuracy: 0.9170\n","Epoch 41/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1219 - accuracy: 0.9552 - val_loss: 0.2564 - val_accuracy: 0.9173\n","Epoch 42/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9545 - val_loss: 0.2648 - val_accuracy: 0.9147\n","Epoch 43/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1167 - accuracy: 0.9555 - val_loss: 0.2641 - val_accuracy: 0.9154\n","Epoch 44/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.9555 - val_loss: 0.2534 - val_accuracy: 0.9170\n","Epoch 45/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9583 - val_loss: 0.2602 - val_accuracy: 0.9174\n","Epoch 46/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9582 - val_loss: 0.2730 - val_accuracy: 0.9136\n","Epoch 47/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1116 - accuracy: 0.9594 - val_loss: 0.2758 - val_accuracy: 0.9142\n","Epoch 48/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9614 - val_loss: 0.2693 - val_accuracy: 0.9158\n","Epoch 49/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9638 - val_loss: 0.2678 - val_accuracy: 0.9142\n","Epoch 50/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.0992 - accuracy: 0.9631 - val_loss: 0.2673 - val_accuracy: 0.9154\n","Epoch 1/50\n","160/160 [==============================] - 2s 10ms/step - loss: 0.9224 - accuracy: 0.6759 - val_loss: 0.4286 - val_accuracy: 0.8499\n","Epoch 2/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.4144 - accuracy: 0.8506 - val_loss: 0.3609 - val_accuracy: 0.8692\n","Epoch 3/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.3707 - accuracy: 0.8660 - val_loss: 0.3181 - val_accuracy: 0.8857\n","Epoch 4/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.8841 - val_loss: 0.2919 - val_accuracy: 0.8929\n","Epoch 5/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2918 - accuracy: 0.8942 - val_loss: 0.2770 - val_accuracy: 0.8976\n","Epoch 6/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2682 - accuracy: 0.9034 - val_loss: 0.2614 - val_accuracy: 0.9027\n","Epoch 7/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2584 - accuracy: 0.9055 - val_loss: 0.2551 - val_accuracy: 0.9066\n","Epoch 8/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2408 - accuracy: 0.9123 - val_loss: 0.2460 - val_accuracy: 0.9093\n","Epoch 9/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2236 - accuracy: 0.9171 - val_loss: 0.2399 - val_accuracy: 0.9120\n","Epoch 10/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2215 - accuracy: 0.9181 - val_loss: 0.2336 - val_accuracy: 0.9151\n","Epoch 11/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.2076 - accuracy: 0.9236 - val_loss: 0.2249 - val_accuracy: 0.9154\n","Epoch 12/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1965 - accuracy: 0.9286 - val_loss: 0.2284 - val_accuracy: 0.9182\n","Epoch 13/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1917 - accuracy: 0.9294 - val_loss: 0.2373 - val_accuracy: 0.9123\n","Epoch 14/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1909 - accuracy: 0.9293 - val_loss: 0.2189 - val_accuracy: 0.9182\n","Epoch 15/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1690 - accuracy: 0.9370 - val_loss: 0.2187 - val_accuracy: 0.9182\n","Epoch 16/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9386 - val_loss: 0.2101 - val_accuracy: 0.9225\n","Epoch 17/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1574 - accuracy: 0.9426 - val_loss: 0.2205 - val_accuracy: 0.9217\n","Epoch 18/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1553 - accuracy: 0.9422 - val_loss: 0.2183 - val_accuracy: 0.9202\n","Epoch 19/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1469 - accuracy: 0.9453 - val_loss: 0.2184 - val_accuracy: 0.9222\n","Epoch 20/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1453 - accuracy: 0.9460 - val_loss: 0.2150 - val_accuracy: 0.9227\n","Epoch 21/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1419 - accuracy: 0.9469 - val_loss: 0.2144 - val_accuracy: 0.9243\n","Epoch 22/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1247 - accuracy: 0.9536 - val_loss: 0.2177 - val_accuracy: 0.9259\n","Epoch 23/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1276 - accuracy: 0.9536 - val_loss: 0.2161 - val_accuracy: 0.9227\n","Epoch 24/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9539 - val_loss: 0.2128 - val_accuracy: 0.9273\n","Epoch 25/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1152 - accuracy: 0.9578 - val_loss: 0.2129 - val_accuracy: 0.9252\n","Epoch 26/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1080 - accuracy: 0.9586 - val_loss: 0.2127 - val_accuracy: 0.9275\n","Epoch 27/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.1059 - accuracy: 0.9612 - val_loss: 0.2254 - val_accuracy: 0.9257\n","Epoch 28/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0994 - accuracy: 0.9623 - val_loss: 0.2230 - val_accuracy: 0.9252\n","Epoch 29/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0970 - accuracy: 0.9635 - val_loss: 0.2292 - val_accuracy: 0.9264\n","Epoch 30/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0924 - accuracy: 0.9656 - val_loss: 0.2172 - val_accuracy: 0.9277\n","Epoch 31/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0898 - accuracy: 0.9669 - val_loss: 0.2243 - val_accuracy: 0.9282\n","Epoch 32/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0814 - accuracy: 0.9704 - val_loss: 0.2265 - val_accuracy: 0.9265\n","Epoch 33/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0815 - accuracy: 0.9695 - val_loss: 0.2384 - val_accuracy: 0.9252\n","Epoch 34/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.2260 - val_accuracy: 0.9285\n","Epoch 35/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0725 - accuracy: 0.9729 - val_loss: 0.2332 - val_accuracy: 0.9265\n","Epoch 36/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0733 - accuracy: 0.9730 - val_loss: 0.2377 - val_accuracy: 0.9288\n","Epoch 37/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9745 - val_loss: 0.2387 - val_accuracy: 0.9291\n","Epoch 38/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0661 - accuracy: 0.9755 - val_loss: 0.2462 - val_accuracy: 0.9269\n","Epoch 39/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9758 - val_loss: 0.2395 - val_accuracy: 0.9296\n","Epoch 40/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9780 - val_loss: 0.2469 - val_accuracy: 0.9249\n","Epoch 41/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0589 - accuracy: 0.9780 - val_loss: 0.2453 - val_accuracy: 0.9295\n","Epoch 42/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0553 - accuracy: 0.9788 - val_loss: 0.2609 - val_accuracy: 0.9249\n","Epoch 43/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.2493 - val_accuracy: 0.9262\n","Epoch 44/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.2585 - val_accuracy: 0.9280\n","Epoch 45/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.2639 - val_accuracy: 0.9285\n","Epoch 46/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0465 - accuracy: 0.9818 - val_loss: 0.2610 - val_accuracy: 0.9268\n","Epoch 47/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0485 - accuracy: 0.9812 - val_loss: 0.2696 - val_accuracy: 0.9255\n","Epoch 48/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.2707 - val_accuracy: 0.9287\n","Epoch 49/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0467 - accuracy: 0.9825 - val_loss: 0.2660 - val_accuracy: 0.9295\n","Epoch 50/50\n","160/160 [==============================] - 1s 8ms/step - loss: 0.0449 - accuracy: 0.9825 - val_loss: 0.2605 - val_accuracy: 0.9283\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGHQlPRz_o5m","executionInfo":{"status":"ok","timestamp":1626864083791,"user_tz":-420,"elapsed":1743,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"566559c5-79b6-431c-f8f3-47cb7b6d3e6e"},"source":["#Evaluation\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 0.29529786109924316\n","Test accuracy: 92.23999977111816\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7yoI5rY1t2uU"},"source":["Model CNN dengan fashion mnist ini melakukan kerja yang baik dengan accuracy 92.23, dan test loss 0.29. Hasil yang memuaskan ini pastinya karena konfigurasi CNN, normalisasi data, dan pengaturan epoch dan batch learning."]},{"cell_type":"markdown","metadata":{"id":"ZMTAnIfT54nh"},"source":["#PCA + CNN"]},{"cell_type":"code","metadata":{"id":"4WLJOo4457WO"},"source":["#Reshape Menjadi 2D untuk dimasukan ke PCA\n","X_train = X_train.reshape(X_train.shape[0], 784)\n","X_test = x_test.reshape(x_test.shape[0], 784)\n","X_validate = X_validate.reshape(X_validate.shape[0], 784)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mma-jRyt6PSv"},"source":["#PCA mengurangi dimensi dari input oleh karena itu kita akan mengubah dari 28x28 menjadi 20x20 maka n_component akan kita setting ke 400\n","pca = PCA(n_components=400)\n","pca = pca.fit(X_train)\n","X_train = pca.transform(X_train)\n","\n","\n","pca = PCA(n_components=400)\n","pca = pca.fit(X_test)\n","X_test = pca.transform(X_test)\n","\n","\n","\n","pca = PCA(n_components=400)\n","pca = pca.fit(X_validate)\n","X_validate = pca.transform(X_validate)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x17ANFkYIdpQ","executionInfo":{"status":"ok","timestamp":1626864295684,"user_tz":-420,"elapsed":327,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"c932987b-c362-41d5-98e8-c79e8befaa92"},"source":["#Reshape features \n","image_rows = 20\n","image_cols = 20\n","input_shape = (image_rows, image_cols, 1)\n","\n","X_train = X_train.reshape(X_train.shape[0], image_rows, image_cols, 1)\n","X_test = X_test.reshape(X_test.shape[0], image_rows, image_cols, 1)\n","X_validate = X_validate.reshape(X_validate.shape[0], image_rows, image_cols, 1)\n","\n","print('x_train shape: {}'.format(X_train.shape))\n","print('x_test shape: {}'.format(X_test.shape))\n","print('x_validate shape: {}'.format(X_validate.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (48000, 20, 20, 1)\n","x_test shape: (10000, 20, 20, 1)\n","x_validate shape: (12000, 20, 20, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IhVfwcEblIUy"},"source":["Pada bagian ini kita akan mengkonfigurasi 2 cnn model kita. "]},{"cell_type":"code","metadata":{"id":"AzrfPu5g4hQC"},"source":["#Pada bagian ini, saya membuat 2 model layer.\n","name = '1_Layer'\n","cnn_model_1 = Sequential([\n","    #Menambahkan layer convulational 2D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.                      \n","    Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","\n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling1D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 32 yang terhubung ketat.\n","    Dense(32, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 10 yaitu jumlah label yang terhubung ketat.\n","    Dense(10, activation='softmax', name='Output')\n","], name=name)\n","\n","name = '2_Layer'\n","cnn_model_2 = Sequential([\n","    #Menambahkan layer convulational 2D dengan 32 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv2D(32, kernel_size=3, activation='relu', input_shape=input_shape, name='Conv2D-1'),\n","    \n","    #Mengurangi dimensional tanpa menghilangkan bagian paling penting dengan size 2*2 \n","    MaxPooling2D(pool_size=2, name='MaxPool'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.2, name='Dropout-1'),\n","\n","    #Menambahkan layer convulational 2D dengan 64 filter , kernel size 3*3 dengan activation relu sebagai default.\n","    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n","\n","    #Mengdrop random neuron untuk mencegah overfitting.\n","    Dropout(0.25, name='Dropout-2'),\n","\n","    #Meratakan 2d menjadi 1 linear vector\n","    Flatten(name='flatten'),\n","\n","    #Menambahkan layer dengan ukuran 64 yang terhubung ketat.\n","    Dense(64, activation='relu', name='Dense'),\n","\n","    #Menambahkan layer dengan ukuran 10 yaitu jumlah label yang terhubung ketat.\n","    Dense(10, activation='softmax', name='Output')\n","], name=name)\n","\n","cnn_PCA_models = [cnn_model_1, cnn_model_2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sjp8Afnu4mcX","executionInfo":{"status":"ok","timestamp":1626864301631,"user_tz":-420,"elapsed":411,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"a42f74c2-ba12-451d-c417-f6b47d3ad7f6"},"source":["#Melihat summary\n","\n","for model in cnn_PCA_models:\n","    model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"1_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 18, 18, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 9, 9, 32)          0         \n","_________________________________________________________________\n","Dropout (Dropout)            (None, 9, 9, 32)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2592)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 32)                82976     \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                330       \n","=================================================================\n","Total params: 83,626\n","Trainable params: 83,626\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"2_Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 18, 18, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 9, 9, 32)          0         \n","_________________________________________________________________\n","Dropout-1 (Dropout)          (None, 9, 9, 32)          0         \n","_________________________________________________________________\n","Conv2D-2 (Conv2D)            (None, 7, 7, 64)          18496     \n","_________________________________________________________________\n","Dropout-2 (Dropout)          (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3136)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 64)                200768    \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                650       \n","=================================================================\n","Total params: 220,234\n","Trainable params: 220,234\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYjNvMTl72nz","executionInfo":{"status":"ok","timestamp":1626864430093,"user_tz":-420,"elapsed":124816,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"7d69e4fd-f2db-4f85-dd95-648978994521"},"source":["#Training Model dan menyimpan di history\n","\n","history_dict = {}\n","\n","for model in cnn_PCA_models:\n","    model.compile(\n","        loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(),\n","        metrics=['accuracy']\n","    )\n","    \n","    history = model.fit(\n","        X_train, y_train,\n","        batch_size=300,\n","        epochs=50, verbose=1,\n","        validation_data=(X_validate, y_validate)\n","    )\n","    \n","    history_dict[model.name] = history"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","160/160 [==============================] - 2s 7ms/step - loss: 1.6857 - accuracy: 0.5106 - val_loss: 1.0119 - val_accuracy: 0.6470\n","Epoch 2/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.6114 - accuracy: 0.7935 - val_loss: 1.0115 - val_accuracy: 0.6526\n","Epoch 3/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5153 - accuracy: 0.8232 - val_loss: 1.0455 - val_accuracy: 0.6568\n","Epoch 4/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4818 - accuracy: 0.8323 - val_loss: 1.0609 - val_accuracy: 0.6530\n","Epoch 5/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4430 - accuracy: 0.8472 - val_loss: 1.0732 - val_accuracy: 0.6528\n","Epoch 6/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4343 - accuracy: 0.8455 - val_loss: 1.0862 - val_accuracy: 0.6456\n","Epoch 7/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4277 - accuracy: 0.8526 - val_loss: 1.1125 - val_accuracy: 0.6378\n","Epoch 8/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8570 - val_loss: 1.1206 - val_accuracy: 0.6370\n","Epoch 9/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4058 - accuracy: 0.8577 - val_loss: 1.1154 - val_accuracy: 0.6388\n","Epoch 10/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8631 - val_loss: 1.1308 - val_accuracy: 0.6347\n","Epoch 11/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8624 - val_loss: 1.1424 - val_accuracy: 0.6364\n","Epoch 12/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3858 - accuracy: 0.8643 - val_loss: 1.1583 - val_accuracy: 0.6239\n","Epoch 13/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8637 - val_loss: 1.1531 - val_accuracy: 0.6332\n","Epoch 14/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8691 - val_loss: 1.1687 - val_accuracy: 0.6287\n","Epoch 15/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3678 - accuracy: 0.8711 - val_loss: 1.2017 - val_accuracy: 0.6208\n","Epoch 16/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3718 - accuracy: 0.8692 - val_loss: 1.1981 - val_accuracy: 0.6219\n","Epoch 17/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3652 - accuracy: 0.8712 - val_loss: 1.1776 - val_accuracy: 0.6273\n","Epoch 18/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3656 - accuracy: 0.8708 - val_loss: 1.2102 - val_accuracy: 0.6217\n","Epoch 19/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3603 - accuracy: 0.8725 - val_loss: 1.2143 - val_accuracy: 0.6186\n","Epoch 20/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3602 - accuracy: 0.8727 - val_loss: 1.2131 - val_accuracy: 0.6193\n","Epoch 21/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3541 - accuracy: 0.8752 - val_loss: 1.2280 - val_accuracy: 0.6143\n","Epoch 22/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3555 - accuracy: 0.8736 - val_loss: 1.2241 - val_accuracy: 0.6183\n","Epoch 23/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8764 - val_loss: 1.2727 - val_accuracy: 0.6139\n","Epoch 24/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8774 - val_loss: 1.2609 - val_accuracy: 0.6188\n","Epoch 25/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8774 - val_loss: 1.2481 - val_accuracy: 0.6185\n","Epoch 26/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8729 - val_loss: 1.2269 - val_accuracy: 0.6264\n","Epoch 27/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3384 - accuracy: 0.8779 - val_loss: 1.2788 - val_accuracy: 0.6184\n","Epoch 28/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.8791 - val_loss: 1.2902 - val_accuracy: 0.6154\n","Epoch 29/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8785 - val_loss: 1.2804 - val_accuracy: 0.6176\n","Epoch 30/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8812 - val_loss: 1.2708 - val_accuracy: 0.6187\n","Epoch 31/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3271 - accuracy: 0.8820 - val_loss: 1.2626 - val_accuracy: 0.6256\n","Epoch 32/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3221 - accuracy: 0.8818 - val_loss: 1.3274 - val_accuracy: 0.6148\n","Epoch 33/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3163 - accuracy: 0.8878 - val_loss: 1.3265 - val_accuracy: 0.6177\n","Epoch 34/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.8838 - val_loss: 1.3430 - val_accuracy: 0.6092\n","Epoch 35/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.8859 - val_loss: 1.3060 - val_accuracy: 0.6162\n","Epoch 36/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3202 - accuracy: 0.8843 - val_loss: 1.3442 - val_accuracy: 0.6139\n","Epoch 37/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3110 - accuracy: 0.8885 - val_loss: 1.3164 - val_accuracy: 0.6185\n","Epoch 38/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3178 - accuracy: 0.8838 - val_loss: 1.3289 - val_accuracy: 0.6147\n","Epoch 39/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8896 - val_loss: 1.3434 - val_accuracy: 0.6202\n","Epoch 40/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.8895 - val_loss: 1.3193 - val_accuracy: 0.6223\n","Epoch 41/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3016 - accuracy: 0.8915 - val_loss: 1.3564 - val_accuracy: 0.6077\n","Epoch 42/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3011 - accuracy: 0.8907 - val_loss: 1.3904 - val_accuracy: 0.6130\n","Epoch 43/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3053 - accuracy: 0.8897 - val_loss: 1.3158 - val_accuracy: 0.6219\n","Epoch 44/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3036 - accuracy: 0.8895 - val_loss: 1.3562 - val_accuracy: 0.6132\n","Epoch 45/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2892 - accuracy: 0.8943 - val_loss: 1.4160 - val_accuracy: 0.6059\n","Epoch 46/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3040 - accuracy: 0.8891 - val_loss: 1.4240 - val_accuracy: 0.6090\n","Epoch 47/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2931 - accuracy: 0.8929 - val_loss: 1.4233 - val_accuracy: 0.6051\n","Epoch 48/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2947 - accuracy: 0.8909 - val_loss: 1.4030 - val_accuracy: 0.6145\n","Epoch 49/50\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.8923 - val_loss: 1.4121 - val_accuracy: 0.6100\n","Epoch 50/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2889 - accuracy: 0.8942 - val_loss: 1.4514 - val_accuracy: 0.6065\n","Epoch 1/50\n","160/160 [==============================] - 2s 8ms/step - loss: 1.5698 - accuracy: 0.4792 - val_loss: 0.9617 - val_accuracy: 0.6568\n","Epoch 2/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.6029 - accuracy: 0.7920 - val_loss: 0.9481 - val_accuracy: 0.6683\n","Epoch 3/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.5085 - accuracy: 0.8220 - val_loss: 0.9833 - val_accuracy: 0.6597\n","Epoch 4/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4752 - accuracy: 0.8303 - val_loss: 0.9595 - val_accuracy: 0.6667\n","Epoch 5/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.4505 - accuracy: 0.8385 - val_loss: 0.9621 - val_accuracy: 0.6635\n","Epoch 6/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.8447 - val_loss: 0.9919 - val_accuracy: 0.6632\n","Epoch 7/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8544 - val_loss: 0.9757 - val_accuracy: 0.6643\n","Epoch 8/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3917 - accuracy: 0.8605 - val_loss: 0.9634 - val_accuracy: 0.6578\n","Epoch 9/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.8647 - val_loss: 1.0055 - val_accuracy: 0.6505\n","Epoch 10/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3710 - accuracy: 0.8678 - val_loss: 1.0299 - val_accuracy: 0.6491\n","Epoch 11/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3544 - accuracy: 0.8723 - val_loss: 1.0029 - val_accuracy: 0.6532\n","Epoch 12/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3508 - accuracy: 0.8726 - val_loss: 1.0059 - val_accuracy: 0.6593\n","Epoch 13/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3407 - accuracy: 0.8794 - val_loss: 1.0335 - val_accuracy: 0.6454\n","Epoch 14/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3295 - accuracy: 0.8805 - val_loss: 1.0407 - val_accuracy: 0.6435\n","Epoch 15/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3228 - accuracy: 0.8830 - val_loss: 1.0867 - val_accuracy: 0.6438\n","Epoch 16/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3161 - accuracy: 0.8849 - val_loss: 1.0574 - val_accuracy: 0.6450\n","Epoch 17/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.3061 - accuracy: 0.8874 - val_loss: 1.0553 - val_accuracy: 0.6422\n","Epoch 18/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2979 - accuracy: 0.8918 - val_loss: 1.0616 - val_accuracy: 0.6399\n","Epoch 19/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2916 - accuracy: 0.8944 - val_loss: 1.0685 - val_accuracy: 0.6460\n","Epoch 20/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8932 - val_loss: 1.0600 - val_accuracy: 0.6389\n","Epoch 21/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2834 - accuracy: 0.8957 - val_loss: 1.0748 - val_accuracy: 0.6378\n","Epoch 22/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2735 - accuracy: 0.8997 - val_loss: 1.0792 - val_accuracy: 0.6443\n","Epoch 23/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2637 - accuracy: 0.9014 - val_loss: 1.1113 - val_accuracy: 0.6325\n","Epoch 24/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2669 - accuracy: 0.9009 - val_loss: 1.1533 - val_accuracy: 0.6321\n","Epoch 25/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2590 - accuracy: 0.9044 - val_loss: 1.1686 - val_accuracy: 0.6326\n","Epoch 26/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2518 - accuracy: 0.9070 - val_loss: 1.1810 - val_accuracy: 0.6359\n","Epoch 27/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2589 - accuracy: 0.9023 - val_loss: 1.2085 - val_accuracy: 0.6284\n","Epoch 28/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2452 - accuracy: 0.9088 - val_loss: 1.2173 - val_accuracy: 0.6324\n","Epoch 29/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2364 - accuracy: 0.9127 - val_loss: 1.1854 - val_accuracy: 0.6360\n","Epoch 30/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2326 - accuracy: 0.9164 - val_loss: 1.2300 - val_accuracy: 0.6295\n","Epoch 31/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2349 - accuracy: 0.9118 - val_loss: 1.2365 - val_accuracy: 0.6263\n","Epoch 32/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2239 - accuracy: 0.9180 - val_loss: 1.2821 - val_accuracy: 0.6292\n","Epoch 33/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2256 - accuracy: 0.9168 - val_loss: 1.2258 - val_accuracy: 0.6305\n","Epoch 34/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9164 - val_loss: 1.3080 - val_accuracy: 0.6233\n","Epoch 35/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2190 - accuracy: 0.9172 - val_loss: 1.2609 - val_accuracy: 0.6263\n","Epoch 36/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.9194 - val_loss: 1.2655 - val_accuracy: 0.6203\n","Epoch 37/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2058 - accuracy: 0.9245 - val_loss: 1.2747 - val_accuracy: 0.6261\n","Epoch 38/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2064 - accuracy: 0.9229 - val_loss: 1.3000 - val_accuracy: 0.6251\n","Epoch 39/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.2090 - accuracy: 0.9216 - val_loss: 1.2975 - val_accuracy: 0.6202\n","Epoch 40/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1979 - accuracy: 0.9273 - val_loss: 1.4003 - val_accuracy: 0.6227\n","Epoch 41/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1959 - accuracy: 0.9261 - val_loss: 1.2863 - val_accuracy: 0.6301\n","Epoch 42/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9263 - val_loss: 1.3043 - val_accuracy: 0.6298\n","Epoch 43/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1863 - accuracy: 0.9304 - val_loss: 1.3562 - val_accuracy: 0.6158\n","Epoch 44/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1921 - accuracy: 0.9284 - val_loss: 1.3443 - val_accuracy: 0.6250\n","Epoch 45/50\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1859 - accuracy: 0.9303 - val_loss: 1.3345 - val_accuracy: 0.6258\n","Epoch 46/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1836 - accuracy: 0.9303 - val_loss: 1.3434 - val_accuracy: 0.6260\n","Epoch 47/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9339 - val_loss: 1.3961 - val_accuracy: 0.6253\n","Epoch 48/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.9322 - val_loss: 1.4922 - val_accuracy: 0.6123\n","Epoch 49/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1793 - accuracy: 0.9329 - val_loss: 1.3878 - val_accuracy: 0.6283\n","Epoch 50/50\n","160/160 [==============================] - 1s 6ms/step - loss: 0.1739 - accuracy: 0.9344 - val_loss: 1.5036 - val_accuracy: 0.6148\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2AVvd88K74jV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626864533581,"user_tz":-420,"elapsed":1302,"user":{"displayName":"Daffa Rizki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiO8ZF06hlqkKJVtO2Rm1cBzF37XQAufwXDgzK0Tg=s64","userId":"12805345379547597214"}},"outputId":"d41ec6d1-7eac-46a3-e1ba-d98e09b62d56"},"source":["#Evaluasi\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1]*100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 1.050186276435852\n","Test accuracy: 68.33000183105469\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8r-Z2U9VunRN"},"source":["Model PCA+CNN saya menghasilkan accuracy 68.33% dengan loss 1. Hasilnya kurang optimal dan dapat dikembangkan dengan memperbanyak training set,mengatur konfigurasi model,mengatur batch learning dan mengatur epoch untuk menghasilkan hasil yang optimal. Untuk PCA+CNN ini , n_components PCA juga pastinya berpengaruh. "]},{"cell_type":"markdown","metadata":{"id":"xVH8lhbgk5pf"},"source":["![image.png](data:image/png;base64,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)\n","\n","Terlihat pada tabel diatas, CNN mengungguli dibanding dengan PCA+CNN. PCA+CNN mendapatkan hasil 66.72%. Sedangkan CNN mendapatkan hasil 92.35%. Model CNN dapat ditingkatkan dengan mengubah konfigurasi CNNnya dan juga mengatur jumlah Batch Learning dan epoch. Sedangkan MOdel PCA+CNN juga sama tapi juga terpengaruhi oleh n_componentsnya. Dengan mengubah dimensi gambar fashion 28x28 ke 20 x20 akan mengurangi variabel yang berkorelasi. PCA sendiri sudah menyederhanakan data dan dapat mengurangi redudansi menjadi data dengan varian yang lebih maksimal, yaitu yang awalnya variable nya berkolerasi, menjadi variable yang bebas atau tidak berkolerasi sehingga hasil kurang bagus. "]}]}